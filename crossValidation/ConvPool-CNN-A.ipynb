{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnnTrain.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "26dd6b177fc946b98ee5a676cd43145c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c5e3f37a07f341829620097ad0b6f64d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e83acaaa5eb448288aba8d1f0baa495c",
              "IPY_MODEL_8ae69a4001f64ac5b7c218edfe55ef12"
            ]
          }
        },
        "c5e3f37a07f341829620097ad0b6f64d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e83acaaa5eb448288aba8d1f0baa495c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f3177e231a984f9fb42cee98448772d3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_63867ddc96db4463b2e01d4f7d03953a"
          }
        },
        "8ae69a4001f64ac5b7c218edfe55ef12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e36b616ecb3441bca57a90318c5bbabc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 97406428.88it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a01f9cfabf3404aa7416d982cff26b9"
          }
        },
        "f3177e231a984f9fb42cee98448772d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "63867ddc96db4463b2e01d4f7d03953a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e36b616ecb3441bca57a90318c5bbabc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a01f9cfabf3404aa7416d982cff26b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wtsyang/dl-reproducibility-project/blob/master/crossValidation/ConvPool-CNN-A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvPp9xKan7AQ",
        "colab_type": "code",
        "outputId": "fe486ee2-4323-4768-e610-e5c315785683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgzmPWLIweMW",
        "colab_type": "code",
        "outputId": "5f769e75-3356-4003-fa2a-061c73b75760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "from google.colab import files\n",
        "try:\n",
        "    from torchsummary import summary\n",
        "except ModuleNotFoundError:\n",
        "    !pip install -q torchsummary\n",
        "    from torchsummary import summary\n",
        "try:\n",
        "    import torch\n",
        "except ModuleNotFoundError:\n",
        "    from os import path\n",
        "    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "    accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "    !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.1-{platform}-linux_x86_64.whl\n",
        "    import torch\n",
        "try:\n",
        "    import torchvision\n",
        "except ModuleNotFoundError:\n",
        "    !pip install -q torchvision\n",
        "try:\n",
        "    import utils\n",
        "except ModuleNotFoundError:\n",
        "    !wget https://raw.githubusercontent.com/StefOe/colab-pytorch-utils/HEAD/utils.py\n",
        "    import utils\n",
        "import torch.nn as nn\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-19 07:52:08--  https://raw.githubusercontent.com/StefOe/colab-pytorch-utils/HEAD/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4519 (4.4K) [text/plain]\n",
            "Saving to: â€˜utils.pyâ€™\n",
            "\n",
            "\rutils.py              0%[                    ]       0  --.-KB/s               \rutils.py            100%[===================>]   4.41K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-19 07:52:08 (78.7 MB/s) - â€˜utils.pyâ€™ saved [4519/4519]\n",
            "\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.38.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye1bNppSqPUt",
        "colab_type": "code",
        "outputId": "02f915a8-14fa-4ca6-940c-146aae59862c",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c920f2da-503a-4f58-96f9-13c9500c9f4c\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-c920f2da-503a-4f58-96f9-13c9500c9f4c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Model.py to Model.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi5ozl43sAFE",
        "colab_type": "code",
        "outputId": "54b76331-42a5-4509-bdac-7dcf98ee3ec9",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c520e837-5280-4846-a4d7-0fda8b326138\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-c520e837-5280-4846-a4d7-0fda8b326138\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Training.py to Training.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-xD01LPXy2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from Model import Model\n",
        "from Training import Training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kI4BhyttQep",
        "colab_type": "code",
        "outputId": "fb127fcd-91af-441f-96a6-09b27b9bd659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs('/content/drive/My Drive/dl-reproducibility-project/model/')\n",
        "except:\n",
        "  print('')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_j0N7zOqomb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training=Training(validation=True,bestModel_allLR=True,baseModel=[True,False,False])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMlh-sj3z0VS",
        "colab_type": "code",
        "outputId": "0ba4141f-e971-4a38-a1ab-a18d5062e246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "26dd6b177fc946b98ee5a676cd43145c",
            "c5e3f37a07f341829620097ad0b6f64d",
            "e83acaaa5eb448288aba8d1f0baa495c",
            "8ae69a4001f64ac5b7c218edfe55ef12",
            "f3177e231a984f9fb42cee98448772d3",
            "63867ddc96db4463b2e01d4f7d03953a",
            "e36b616ecb3441bca57a90318c5bbabc",
            "7a01f9cfabf3404aa7416d982cff26b9"
          ]
        }
      },
      "source": [
        "training.createDataset()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26dd6b177fc946b98ee5a676cd43145c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./cifar10/cifar-10-python.tar.gz to ./cifar10\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ0jPxALa-2z",
        "colab_type": "text"
      },
      "source": [
        "### ALL-CNN-A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPs2iB5RREhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training.lrPair=[0.05, 0.01]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fvap_DBju8IB",
        "colab_type": "code",
        "outputId": "ad20296a-6774-41ae-b845-2e5e1d382b21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "training.modifiedModel=[False,False,False,True]\n",
        "training.Procedure()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training with  0.05\n",
            "Model(\n",
            "  (model): Sequential(\n",
            "    (0): Dropout(p=0.2, inplace=False)\n",
            "    (1): Conv2d(3, 96, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (2): ReLU()\n",
            "    (3): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Conv2d(96, 192, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU()\n",
            "    (8): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
            "    (9): ReLU()\n",
            "    (10): Dropout(p=0.5, inplace=False)\n",
            "    (11): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (12): ReLU()\n",
            "    (13): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (14): ReLU()\n",
            "    (15): Conv2d(192, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (16): ReLU()\n",
            "    (17): AdaptiveAvgPool2d(output_size=1)\n",
            "    (18): Flatten()\n",
            "  )\n",
            "  (conv_3_192_192_1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv_1_192_192): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (conv_1_192_class): Conv2d(192, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (BN_96): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (BN_192): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (BN_class): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (maxP): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (softMax): Softmax(dim=None)\n",
            "  (flatten): Flatten()\n",
            "  (dropOut_2): Dropout(p=0.2, inplace=False)\n",
            "  (dropOut_5): Dropout(p=0.5, inplace=False)\n",
            "  (relu): ReLU()\n",
            "  (avgPooling): AdaptiveAvgPool2d(output_size=1)\n",
            "  (conv_5_Input_96_1): Conv2d(3, 96, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "  (conv_5_96_192_1): Conv2d(96, 192, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "  (conv_5_96_96_2): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
            "  (conv_5_192_192_2): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "           Dropout-1            [-1, 3, 32, 32]               0\n",
            "            Conv2d-2           [-1, 96, 30, 30]           7,296\n",
            "              ReLU-3           [-1, 96, 30, 30]               0\n",
            "            Conv2d-4           [-1, 96, 14, 14]         230,496\n",
            "              ReLU-5           [-1, 96, 14, 14]               0\n",
            "           Dropout-6           [-1, 96, 14, 14]               0\n",
            "            Conv2d-7          [-1, 192, 12, 12]         460,992\n",
            "              ReLU-8          [-1, 192, 12, 12]               0\n",
            "            Conv2d-9            [-1, 192, 5, 5]         921,792\n",
            "             ReLU-10            [-1, 192, 5, 5]               0\n",
            "          Dropout-11            [-1, 192, 5, 5]               0\n",
            "           Conv2d-12            [-1, 192, 5, 5]         331,968\n",
            "             ReLU-13            [-1, 192, 5, 5]               0\n",
            "           Conv2d-14            [-1, 192, 5, 5]          37,056\n",
            "             ReLU-15            [-1, 192, 5, 5]               0\n",
            "           Conv2d-16             [-1, 10, 5, 5]           1,930\n",
            "             ReLU-17             [-1, 10, 5, 5]               0\n",
            "AdaptiveAvgPool2d-18             [-1, 10, 1, 1]               0\n",
            "          Flatten-19                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 1,991,530\n",
            "Trainable params: 1,991,530\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.45\n",
            "Params size (MB): 7.60\n",
            "Estimated Total Size (MB): 10.06\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/47500 (0%)]\tLoss: 2.303201\n",
            "Train Epoch: 0 [25600/47500 (54%)]\tLoss: 2.302925\n",
            "\n",
            "Valid set: Average loss: 0.0367, Accuracy: 318/2499 (13%)\n",
            "\n",
            "Train Epoch: 1 [0/47500 (0%)]\tLoss: 2.291133\n",
            "Train Epoch: 1 [25600/47500 (54%)]\tLoss: 2.074333\n",
            "\n",
            "Valid set: Average loss: 0.0304, Accuracy: 648/2499 (26%)\n",
            "\n",
            "Train Epoch: 2 [0/47500 (0%)]\tLoss: 1.910926\n",
            "Train Epoch: 2 [25600/47500 (54%)]\tLoss: 1.782036\n",
            "\n",
            "Valid set: Average loss: 0.0264, Accuracy: 974/2499 (39%)\n",
            "\n",
            "Train Epoch: 3 [0/47500 (0%)]\tLoss: 1.639866\n",
            "Train Epoch: 3 [25600/47500 (54%)]\tLoss: 1.575502\n",
            "\n",
            "Valid set: Average loss: 0.0230, Accuracy: 1220/2499 (49%)\n",
            "\n",
            "Train Epoch: 4 [0/47500 (0%)]\tLoss: 1.404924\n",
            "Train Epoch: 4 [25600/47500 (54%)]\tLoss: 1.328891\n",
            "\n",
            "Valid set: Average loss: 0.0200, Accuracy: 1398/2499 (56%)\n",
            "\n",
            "Train Epoch: 5 [0/47500 (0%)]\tLoss: 1.386539\n",
            "Train Epoch: 5 [25600/47500 (54%)]\tLoss: 1.408513\n",
            "\n",
            "Valid set: Average loss: 0.0220, Accuracy: 1287/2499 (52%)\n",
            "\n",
            "Train Epoch: 6 [0/47500 (0%)]\tLoss: 1.234904\n",
            "Train Epoch: 6 [25600/47500 (54%)]\tLoss: 1.147278\n",
            "\n",
            "Valid set: Average loss: 0.0180, Accuracy: 1489/2499 (60%)\n",
            "\n",
            "Train Epoch: 7 [0/47500 (0%)]\tLoss: 1.160573\n",
            "Train Epoch: 7 [25600/47500 (54%)]\tLoss: 1.260769\n",
            "\n",
            "Valid set: Average loss: 0.0179, Accuracy: 1526/2499 (61%)\n",
            "\n",
            "Train Epoch: 8 [0/47500 (0%)]\tLoss: 1.083475\n",
            "Train Epoch: 8 [25600/47500 (54%)]\tLoss: 1.062626\n",
            "\n",
            "Valid set: Average loss: 0.0181, Accuracy: 1545/2499 (62%)\n",
            "\n",
            "Train Epoch: 9 [0/47500 (0%)]\tLoss: 1.046676\n",
            "Train Epoch: 9 [25600/47500 (54%)]\tLoss: 0.981417\n",
            "\n",
            "Valid set: Average loss: 0.0150, Accuracy: 1713/2499 (69%)\n",
            "\n",
            "Train Epoch: 10 [0/47500 (0%)]\tLoss: 0.783155\n",
            "Train Epoch: 10 [25600/47500 (54%)]\tLoss: 0.850383\n",
            "\n",
            "Valid set: Average loss: 0.0152, Accuracy: 1669/2499 (67%)\n",
            "\n",
            "Train Epoch: 11 [0/47500 (0%)]\tLoss: 0.749731\n",
            "Train Epoch: 11 [25600/47500 (54%)]\tLoss: 0.911699\n",
            "\n",
            "Valid set: Average loss: 0.0134, Accuracy: 1802/2499 (72%)\n",
            "\n",
            "Train Epoch: 12 [0/47500 (0%)]\tLoss: 0.780315\n",
            "Train Epoch: 12 [25600/47500 (54%)]\tLoss: 0.800732\n",
            "\n",
            "Valid set: Average loss: 0.0132, Accuracy: 1814/2499 (73%)\n",
            "\n",
            "Train Epoch: 13 [0/47500 (0%)]\tLoss: 0.786040\n",
            "Train Epoch: 13 [25600/47500 (54%)]\tLoss: 0.771368\n",
            "\n",
            "Valid set: Average loss: 0.0124, Accuracy: 1833/2499 (73%)\n",
            "\n",
            "Train Epoch: 14 [0/47500 (0%)]\tLoss: 0.731753\n",
            "Train Epoch: 14 [25600/47500 (54%)]\tLoss: 0.884442\n",
            "\n",
            "Valid set: Average loss: 0.0134, Accuracy: 1817/2499 (73%)\n",
            "\n",
            "Train Epoch: 15 [0/47500 (0%)]\tLoss: 0.838041\n",
            "Train Epoch: 15 [25600/47500 (54%)]\tLoss: 0.782322\n",
            "\n",
            "Valid set: Average loss: 0.0134, Accuracy: 1790/2499 (72%)\n",
            "\n",
            "Train Epoch: 16 [0/47500 (0%)]\tLoss: 0.838417\n",
            "Train Epoch: 16 [25600/47500 (54%)]\tLoss: 0.655141\n",
            "\n",
            "Valid set: Average loss: 0.0119, Accuracy: 1874/2499 (75%)\n",
            "\n",
            "Train Epoch: 17 [0/47500 (0%)]\tLoss: 0.731682\n",
            "Train Epoch: 17 [25600/47500 (54%)]\tLoss: 0.832313\n",
            "\n",
            "Valid set: Average loss: 0.0123, Accuracy: 1862/2499 (75%)\n",
            "\n",
            "Train Epoch: 18 [0/47500 (0%)]\tLoss: 0.619614\n",
            "Train Epoch: 18 [25600/47500 (54%)]\tLoss: 0.697094\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 1934/2499 (77%)\n",
            "\n",
            "Train Epoch: 19 [0/47500 (0%)]\tLoss: 0.756578\n",
            "Train Epoch: 19 [25600/47500 (54%)]\tLoss: 0.830872\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 1942/2499 (78%)\n",
            "\n",
            "Train Epoch: 20 [0/47500 (0%)]\tLoss: 0.716175\n",
            "Train Epoch: 20 [25600/47500 (54%)]\tLoss: 0.693563\n",
            "\n",
            "Valid set: Average loss: 0.0121, Accuracy: 1869/2499 (75%)\n",
            "\n",
            "Train Epoch: 21 [0/47500 (0%)]\tLoss: 0.637430\n",
            "Train Epoch: 21 [25600/47500 (54%)]\tLoss: 0.629106\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 1942/2499 (78%)\n",
            "\n",
            "Train Epoch: 22 [0/47500 (0%)]\tLoss: 0.541107\n",
            "Train Epoch: 22 [25600/47500 (54%)]\tLoss: 0.781153\n",
            "\n",
            "Valid set: Average loss: 0.0116, Accuracy: 1909/2499 (76%)\n",
            "\n",
            "Train Epoch: 23 [0/47500 (0%)]\tLoss: 0.625479\n",
            "Train Epoch: 23 [25600/47500 (54%)]\tLoss: 0.611782\n",
            "\n",
            "Valid set: Average loss: 0.0110, Accuracy: 1931/2499 (77%)\n",
            "\n",
            "Train Epoch: 24 [0/47500 (0%)]\tLoss: 0.635095\n",
            "Train Epoch: 24 [25600/47500 (54%)]\tLoss: 0.661751\n",
            "\n",
            "Valid set: Average loss: 0.0115, Accuracy: 1893/2499 (76%)\n",
            "\n",
            "Train Epoch: 25 [0/47500 (0%)]\tLoss: 0.691994\n",
            "Train Epoch: 25 [25600/47500 (54%)]\tLoss: 0.663845\n",
            "\n",
            "Valid set: Average loss: 0.0112, Accuracy: 1929/2499 (77%)\n",
            "\n",
            "Train Epoch: 26 [0/47500 (0%)]\tLoss: 0.789863\n",
            "Train Epoch: 26 [25600/47500 (54%)]\tLoss: 0.659892\n",
            "\n",
            "Valid set: Average loss: 0.0106, Accuracy: 1936/2499 (77%)\n",
            "\n",
            "Train Epoch: 27 [0/47500 (0%)]\tLoss: 0.583322\n",
            "Train Epoch: 27 [25600/47500 (54%)]\tLoss: 0.724531\n",
            "\n",
            "Valid set: Average loss: 0.0103, Accuracy: 1995/2499 (80%)\n",
            "\n",
            "Train Epoch: 28 [0/47500 (0%)]\tLoss: 0.667131\n",
            "Train Epoch: 28 [25600/47500 (54%)]\tLoss: 0.578662\n",
            "\n",
            "Valid set: Average loss: 0.0097, Accuracy: 1993/2499 (80%)\n",
            "\n",
            "Train Epoch: 29 [0/47500 (0%)]\tLoss: 0.584683\n",
            "Train Epoch: 29 [25600/47500 (54%)]\tLoss: 0.578173\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 1961/2499 (78%)\n",
            "\n",
            "Train Epoch: 30 [0/47500 (0%)]\tLoss: 0.677300\n",
            "Train Epoch: 30 [25600/47500 (54%)]\tLoss: 0.694410\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 1974/2499 (79%)\n",
            "\n",
            "Train Epoch: 31 [0/47500 (0%)]\tLoss: 0.715751\n",
            "Train Epoch: 31 [25600/47500 (54%)]\tLoss: 0.618512\n",
            "\n",
            "Valid set: Average loss: 0.0098, Accuracy: 2004/2499 (80%)\n",
            "\n",
            "Train Epoch: 32 [0/47500 (0%)]\tLoss: 0.585359\n",
            "Train Epoch: 32 [25600/47500 (54%)]\tLoss: 0.573040\n",
            "\n",
            "Valid set: Average loss: 0.0106, Accuracy: 1977/2499 (79%)\n",
            "\n",
            "Train Epoch: 33 [0/47500 (0%)]\tLoss: 0.683055\n",
            "Train Epoch: 33 [25600/47500 (54%)]\tLoss: 0.533832\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 1998/2499 (80%)\n",
            "\n",
            "Train Epoch: 34 [0/47500 (0%)]\tLoss: 0.595665\n",
            "Train Epoch: 34 [25600/47500 (54%)]\tLoss: 0.654649\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 1954/2499 (78%)\n",
            "\n",
            "Train Epoch: 35 [0/47500 (0%)]\tLoss: 0.522475\n",
            "Train Epoch: 35 [25600/47500 (54%)]\tLoss: 0.541655\n",
            "\n",
            "Valid set: Average loss: 0.0106, Accuracy: 1949/2499 (78%)\n",
            "\n",
            "Train Epoch: 36 [0/47500 (0%)]\tLoss: 0.513334\n",
            "Train Epoch: 36 [25600/47500 (54%)]\tLoss: 0.551051\n",
            "\n",
            "Valid set: Average loss: 0.0100, Accuracy: 1999/2499 (80%)\n",
            "\n",
            "Train Epoch: 37 [0/47500 (0%)]\tLoss: 0.482797\n",
            "Train Epoch: 37 [25600/47500 (54%)]\tLoss: 0.571014\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2001/2499 (80%)\n",
            "\n",
            "Train Epoch: 38 [0/47500 (0%)]\tLoss: 0.483259\n",
            "Train Epoch: 38 [25600/47500 (54%)]\tLoss: 0.592061\n",
            "\n",
            "Valid set: Average loss: 0.0100, Accuracy: 1999/2499 (80%)\n",
            "\n",
            "Train Epoch: 39 [0/47500 (0%)]\tLoss: 0.471689\n",
            "Train Epoch: 39 [25600/47500 (54%)]\tLoss: 0.511944\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 1999/2499 (80%)\n",
            "\n",
            "Train Epoch: 40 [0/47500 (0%)]\tLoss: 0.448721\n",
            "Train Epoch: 40 [25600/47500 (54%)]\tLoss: 0.629803\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 1990/2499 (80%)\n",
            "\n",
            "Train Epoch: 41 [0/47500 (0%)]\tLoss: 0.546720\n",
            "Train Epoch: 41 [25600/47500 (54%)]\tLoss: 0.593712\n",
            "\n",
            "Valid set: Average loss: 0.0093, Accuracy: 2014/2499 (81%)\n",
            "\n",
            "Train Epoch: 42 [0/47500 (0%)]\tLoss: 0.423651\n",
            "Train Epoch: 42 [25600/47500 (54%)]\tLoss: 0.434947\n",
            "\n",
            "Valid set: Average loss: 0.0094, Accuracy: 2006/2499 (80%)\n",
            "\n",
            "Train Epoch: 43 [0/47500 (0%)]\tLoss: 0.533432\n",
            "Train Epoch: 43 [25600/47500 (54%)]\tLoss: 0.515749\n",
            "\n",
            "Valid set: Average loss: 0.0099, Accuracy: 2011/2499 (80%)\n",
            "\n",
            "Train Epoch: 44 [0/47500 (0%)]\tLoss: 0.417699\n",
            "Train Epoch: 44 [25600/47500 (54%)]\tLoss: 0.666505\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 1981/2499 (79%)\n",
            "\n",
            "Train Epoch: 45 [0/47500 (0%)]\tLoss: 0.429789\n",
            "Train Epoch: 45 [25600/47500 (54%)]\tLoss: 0.382642\n",
            "\n",
            "Valid set: Average loss: 0.0097, Accuracy: 2007/2499 (80%)\n",
            "\n",
            "Train Epoch: 46 [0/47500 (0%)]\tLoss: 0.415591\n",
            "Train Epoch: 46 [25600/47500 (54%)]\tLoss: 0.526536\n",
            "\n",
            "Valid set: Average loss: 0.0093, Accuracy: 2036/2499 (81%)\n",
            "\n",
            "Train Epoch: 47 [0/47500 (0%)]\tLoss: 0.520798\n",
            "Train Epoch: 47 [25600/47500 (54%)]\tLoss: 0.698194\n",
            "\n",
            "Valid set: Average loss: 0.0096, Accuracy: 2026/2499 (81%)\n",
            "\n",
            "Train Epoch: 48 [0/47500 (0%)]\tLoss: 0.462012\n",
            "Train Epoch: 48 [25600/47500 (54%)]\tLoss: 0.486555\n",
            "\n",
            "Valid set: Average loss: 0.0094, Accuracy: 2027/2499 (81%)\n",
            "\n",
            "Train Epoch: 49 [0/47500 (0%)]\tLoss: 0.509322\n",
            "Train Epoch: 49 [25600/47500 (54%)]\tLoss: 0.474600\n",
            "\n",
            "Valid set: Average loss: 0.0095, Accuracy: 2050/2499 (82%)\n",
            "\n",
            "Train Epoch: 50 [0/47500 (0%)]\tLoss: 0.375317\n",
            "Train Epoch: 50 [25600/47500 (54%)]\tLoss: 0.582366\n",
            "\n",
            "Valid set: Average loss: 0.0091, Accuracy: 2033/2499 (81%)\n",
            "\n",
            "Train Epoch: 51 [0/47500 (0%)]\tLoss: 0.521384\n",
            "Train Epoch: 51 [25600/47500 (54%)]\tLoss: 0.471282\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 1980/2499 (79%)\n",
            "\n",
            "Train Epoch: 52 [0/47500 (0%)]\tLoss: 0.542335\n",
            "Train Epoch: 52 [25600/47500 (54%)]\tLoss: 0.517671\n",
            "\n",
            "Valid set: Average loss: 0.0090, Accuracy: 2047/2499 (82%)\n",
            "\n",
            "Train Epoch: 53 [0/47500 (0%)]\tLoss: 0.512024\n",
            "Train Epoch: 53 [25600/47500 (54%)]\tLoss: 0.541312\n",
            "\n",
            "Valid set: Average loss: 0.0097, Accuracy: 2043/2499 (82%)\n",
            "\n",
            "Train Epoch: 54 [0/47500 (0%)]\tLoss: 0.537112\n",
            "Train Epoch: 54 [25600/47500 (54%)]\tLoss: 0.573241\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2001/2499 (80%)\n",
            "\n",
            "Train Epoch: 55 [0/47500 (0%)]\tLoss: 0.506469\n",
            "Train Epoch: 55 [25600/47500 (54%)]\tLoss: 0.371581\n",
            "\n",
            "Valid set: Average loss: 0.0099, Accuracy: 2024/2499 (81%)\n",
            "\n",
            "Train Epoch: 56 [0/47500 (0%)]\tLoss: 0.459664\n",
            "Train Epoch: 56 [25600/47500 (54%)]\tLoss: 0.417547\n",
            "\n",
            "Valid set: Average loss: 0.0103, Accuracy: 2018/2499 (81%)\n",
            "\n",
            "Train Epoch: 57 [0/47500 (0%)]\tLoss: 0.403410\n",
            "Train Epoch: 57 [25600/47500 (54%)]\tLoss: 0.447715\n",
            "\n",
            "Valid set: Average loss: 0.0096, Accuracy: 2023/2499 (81%)\n",
            "\n",
            "Train Epoch: 58 [0/47500 (0%)]\tLoss: 0.466928\n",
            "Train Epoch: 58 [25600/47500 (54%)]\tLoss: 0.480169\n",
            "\n",
            "Valid set: Average loss: 0.0095, Accuracy: 2033/2499 (81%)\n",
            "\n",
            "Train Epoch: 59 [0/47500 (0%)]\tLoss: 0.434031\n",
            "Train Epoch: 59 [25600/47500 (54%)]\tLoss: 0.447356\n",
            "\n",
            "Valid set: Average loss: 0.0110, Accuracy: 1970/2499 (79%)\n",
            "\n",
            "Train Epoch: 60 [0/47500 (0%)]\tLoss: 0.466345\n",
            "Train Epoch: 60 [25600/47500 (54%)]\tLoss: 0.451932\n",
            "\n",
            "Valid set: Average loss: 0.0093, Accuracy: 2058/2499 (82%)\n",
            "\n",
            "Train Epoch: 61 [0/47500 (0%)]\tLoss: 0.527771\n",
            "Train Epoch: 61 [25600/47500 (54%)]\tLoss: 0.520411\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 2006/2499 (80%)\n",
            "\n",
            "Train Epoch: 62 [0/47500 (0%)]\tLoss: 0.554697\n",
            "Train Epoch: 62 [25600/47500 (54%)]\tLoss: 0.507559\n",
            "\n",
            "Valid set: Average loss: 0.0106, Accuracy: 2007/2499 (80%)\n",
            "\n",
            "Train Epoch: 63 [0/47500 (0%)]\tLoss: 0.458585\n",
            "Train Epoch: 63 [25600/47500 (54%)]\tLoss: 0.479309\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 1998/2499 (80%)\n",
            "\n",
            "Train Epoch: 64 [0/47500 (0%)]\tLoss: 0.466876\n",
            "Train Epoch: 64 [25600/47500 (54%)]\tLoss: 0.464782\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2033/2499 (81%)\n",
            "\n",
            "Train Epoch: 65 [0/47500 (0%)]\tLoss: 0.493286\n",
            "Train Epoch: 65 [25600/47500 (54%)]\tLoss: 0.442032\n",
            "\n",
            "Valid set: Average loss: 0.0093, Accuracy: 2042/2499 (82%)\n",
            "\n",
            "Train Epoch: 66 [0/47500 (0%)]\tLoss: 0.500518\n",
            "Train Epoch: 66 [25600/47500 (54%)]\tLoss: 0.452082\n",
            "\n",
            "Valid set: Average loss: 0.0103, Accuracy: 2025/2499 (81%)\n",
            "\n",
            "Train Epoch: 67 [0/47500 (0%)]\tLoss: 0.496736\n",
            "Train Epoch: 67 [25600/47500 (54%)]\tLoss: 0.424932\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 1988/2499 (80%)\n",
            "\n",
            "Train Epoch: 68 [0/47500 (0%)]\tLoss: 0.463367\n",
            "Train Epoch: 68 [25600/47500 (54%)]\tLoss: 0.454048\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2012/2499 (81%)\n",
            "\n",
            "Train Epoch: 69 [0/47500 (0%)]\tLoss: 0.403181\n",
            "Train Epoch: 69 [25600/47500 (54%)]\tLoss: 0.470060\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2046/2499 (82%)\n",
            "\n",
            "Train Epoch: 70 [0/47500 (0%)]\tLoss: 0.560343\n",
            "Train Epoch: 70 [25600/47500 (54%)]\tLoss: 0.457394\n",
            "\n",
            "Valid set: Average loss: 0.0103, Accuracy: 2023/2499 (81%)\n",
            "\n",
            "Train Epoch: 71 [0/47500 (0%)]\tLoss: 0.533072\n",
            "Train Epoch: 71 [25600/47500 (54%)]\tLoss: 0.453232\n",
            "\n",
            "Valid set: Average loss: 0.0097, Accuracy: 2028/2499 (81%)\n",
            "\n",
            "Train Epoch: 72 [0/47500 (0%)]\tLoss: 0.336951\n",
            "Train Epoch: 72 [25600/47500 (54%)]\tLoss: 0.472578\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2047/2499 (82%)\n",
            "\n",
            "Train Epoch: 73 [0/47500 (0%)]\tLoss: 0.311151\n",
            "Train Epoch: 73 [25600/47500 (54%)]\tLoss: 0.438552\n",
            "\n",
            "Valid set: Average loss: 0.0095, Accuracy: 2037/2499 (82%)\n",
            "\n",
            "Train Epoch: 74 [0/47500 (0%)]\tLoss: 0.481741\n",
            "Train Epoch: 74 [25600/47500 (54%)]\tLoss: 0.420382\n",
            "\n",
            "Valid set: Average loss: 0.0090, Accuracy: 2060/2499 (82%)\n",
            "\n",
            "Train Epoch: 75 [0/47500 (0%)]\tLoss: 0.336940\n",
            "Train Epoch: 75 [25600/47500 (54%)]\tLoss: 0.449379\n",
            "\n",
            "Valid set: Average loss: 0.0106, Accuracy: 2055/2499 (82%)\n",
            "\n",
            "Train Epoch: 76 [0/47500 (0%)]\tLoss: 0.382597\n",
            "Train Epoch: 76 [25600/47500 (54%)]\tLoss: 0.405784\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2011/2499 (80%)\n",
            "\n",
            "Train Epoch: 77 [0/47500 (0%)]\tLoss: 0.384571\n",
            "Train Epoch: 77 [25600/47500 (54%)]\tLoss: 0.399269\n",
            "\n",
            "Valid set: Average loss: 0.0100, Accuracy: 2031/2499 (81%)\n",
            "\n",
            "Train Epoch: 78 [0/47500 (0%)]\tLoss: 0.436500\n",
            "Train Epoch: 78 [25600/47500 (54%)]\tLoss: 0.450972\n",
            "\n",
            "Valid set: Average loss: 0.0103, Accuracy: 2013/2499 (81%)\n",
            "\n",
            "Train Epoch: 79 [0/47500 (0%)]\tLoss: 0.520712\n",
            "Train Epoch: 79 [25600/47500 (54%)]\tLoss: 0.399664\n",
            "\n",
            "Valid set: Average loss: 0.0096, Accuracy: 2036/2499 (81%)\n",
            "\n",
            "Train Epoch: 80 [0/47500 (0%)]\tLoss: 0.413820\n",
            "Train Epoch: 80 [25600/47500 (54%)]\tLoss: 0.377819\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2061/2499 (82%)\n",
            "\n",
            "Train Epoch: 81 [0/47500 (0%)]\tLoss: 0.370055\n",
            "Train Epoch: 81 [25600/47500 (54%)]\tLoss: 0.443403\n",
            "\n",
            "Valid set: Average loss: 0.0095, Accuracy: 2036/2499 (81%)\n",
            "\n",
            "Train Epoch: 82 [0/47500 (0%)]\tLoss: 0.411548\n",
            "Train Epoch: 82 [25600/47500 (54%)]\tLoss: 0.344895\n",
            "\n",
            "Valid set: Average loss: 0.0103, Accuracy: 2039/2499 (82%)\n",
            "\n",
            "Train Epoch: 83 [0/47500 (0%)]\tLoss: 0.356043\n",
            "Train Epoch: 83 [25600/47500 (54%)]\tLoss: 0.366712\n",
            "\n",
            "Valid set: Average loss: 0.0099, Accuracy: 2050/2499 (82%)\n",
            "\n",
            "Train Epoch: 84 [0/47500 (0%)]\tLoss: 0.466105\n",
            "Train Epoch: 84 [25600/47500 (54%)]\tLoss: 0.487558\n",
            "\n",
            "Valid set: Average loss: 0.0097, Accuracy: 2020/2499 (81%)\n",
            "\n",
            "Train Epoch: 85 [0/47500 (0%)]\tLoss: 0.399582\n",
            "Train Epoch: 85 [25600/47500 (54%)]\tLoss: 0.447437\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2036/2499 (81%)\n",
            "\n",
            "Train Epoch: 86 [0/47500 (0%)]\tLoss: 0.420052\n",
            "Train Epoch: 86 [25600/47500 (54%)]\tLoss: 0.598983\n",
            "\n",
            "Valid set: Average loss: 0.0098, Accuracy: 2040/2499 (82%)\n",
            "\n",
            "Train Epoch: 87 [0/47500 (0%)]\tLoss: 0.396111\n",
            "Train Epoch: 87 [25600/47500 (54%)]\tLoss: 0.486714\n",
            "\n",
            "Valid set: Average loss: 0.0098, Accuracy: 2077/2499 (83%)\n",
            "\n",
            "Train Epoch: 88 [0/47500 (0%)]\tLoss: 0.438205\n",
            "Train Epoch: 88 [25600/47500 (54%)]\tLoss: 0.424927\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2020/2499 (81%)\n",
            "\n",
            "Train Epoch: 89 [0/47500 (0%)]\tLoss: 0.330295\n",
            "Train Epoch: 89 [25600/47500 (54%)]\tLoss: 0.426706\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2060/2499 (82%)\n",
            "\n",
            "Train Epoch: 90 [0/47500 (0%)]\tLoss: 0.396951\n",
            "Train Epoch: 90 [25600/47500 (54%)]\tLoss: 0.392321\n",
            "\n",
            "Valid set: Average loss: 0.0097, Accuracy: 2033/2499 (81%)\n",
            "\n",
            "Train Epoch: 91 [0/47500 (0%)]\tLoss: 0.499105\n",
            "Train Epoch: 91 [25600/47500 (54%)]\tLoss: 0.461286\n",
            "\n",
            "Valid set: Average loss: 0.0091, Accuracy: 2046/2499 (82%)\n",
            "\n",
            "Train Epoch: 92 [0/47500 (0%)]\tLoss: 0.453185\n",
            "Train Epoch: 92 [25600/47500 (54%)]\tLoss: 0.365550\n",
            "\n",
            "Valid set: Average loss: 0.0100, Accuracy: 2053/2499 (82%)\n",
            "\n",
            "Train Epoch: 93 [0/47500 (0%)]\tLoss: 0.445681\n",
            "Train Epoch: 93 [25600/47500 (54%)]\tLoss: 0.351628\n",
            "\n",
            "Valid set: Average loss: 0.0095, Accuracy: 2055/2499 (82%)\n",
            "\n",
            "Train Epoch: 94 [0/47500 (0%)]\tLoss: 0.454504\n",
            "Train Epoch: 94 [25600/47500 (54%)]\tLoss: 0.358233\n",
            "\n",
            "Valid set: Average loss: 0.0097, Accuracy: 2043/2499 (82%)\n",
            "\n",
            "Train Epoch: 95 [0/47500 (0%)]\tLoss: 0.488668\n",
            "Train Epoch: 95 [25600/47500 (54%)]\tLoss: 0.315933\n",
            "\n",
            "Valid set: Average loss: 0.0100, Accuracy: 2048/2499 (82%)\n",
            "\n",
            "Train Epoch: 96 [0/47500 (0%)]\tLoss: 0.395699\n",
            "Train Epoch: 96 [25600/47500 (54%)]\tLoss: 0.469926\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 2034/2499 (81%)\n",
            "\n",
            "Train Epoch: 97 [0/47500 (0%)]\tLoss: 0.304984\n",
            "Train Epoch: 97 [25600/47500 (54%)]\tLoss: 0.440504\n",
            "\n",
            "Valid set: Average loss: 0.0115, Accuracy: 1993/2499 (80%)\n",
            "\n",
            "Train Epoch: 98 [0/47500 (0%)]\tLoss: 0.507401\n",
            "Train Epoch: 98 [25600/47500 (54%)]\tLoss: 0.374970\n",
            "\n",
            "Valid set: Average loss: 0.0097, Accuracy: 2034/2499 (81%)\n",
            "\n",
            "Train Epoch: 99 [0/47500 (0%)]\tLoss: 0.540955\n",
            "Train Epoch: 99 [25600/47500 (54%)]\tLoss: 0.501236\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2021/2499 (81%)\n",
            "\n",
            "Train Epoch: 100 [0/47500 (0%)]\tLoss: 0.345784\n",
            "Train Epoch: 100 [25600/47500 (54%)]\tLoss: 0.449702\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2049/2499 (82%)\n",
            "\n",
            "Train Epoch: 101 [0/47500 (0%)]\tLoss: 0.381482\n",
            "Train Epoch: 101 [25600/47500 (54%)]\tLoss: 0.427213\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 2002/2499 (80%)\n",
            "\n",
            "Train Epoch: 102 [0/47500 (0%)]\tLoss: 0.348950\n",
            "Train Epoch: 102 [25600/47500 (54%)]\tLoss: 0.442471\n",
            "\n",
            "Valid set: Average loss: 0.0086, Accuracy: 2078/2499 (83%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Uploading file best_0.05.pt:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Uploading file best_0.05.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:01<00:00, 87.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failed to delete the file\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 103 [0/47500 (0%)]\tLoss: 0.393994\n",
            "Train Epoch: 103 [25600/47500 (54%)]\tLoss: 0.404331\n",
            "\n",
            "Valid set: Average loss: 0.0093, Accuracy: 2066/2499 (83%)\n",
            "\n",
            "Train Epoch: 104 [0/47500 (0%)]\tLoss: 0.407399\n",
            "Train Epoch: 104 [25600/47500 (54%)]\tLoss: 0.338145\n",
            "\n",
            "Valid set: Average loss: 0.0098, Accuracy: 2031/2499 (81%)\n",
            "\n",
            "Train Epoch: 105 [0/47500 (0%)]\tLoss: 0.330258\n",
            "Train Epoch: 105 [25600/47500 (54%)]\tLoss: 0.344674\n",
            "\n",
            "Valid set: Average loss: 0.0091, Accuracy: 2072/2499 (83%)\n",
            "\n",
            "Train Epoch: 106 [0/47500 (0%)]\tLoss: 0.425549\n",
            "Train Epoch: 106 [25600/47500 (54%)]\tLoss: 0.340986\n",
            "\n",
            "Valid set: Average loss: 0.0109, Accuracy: 2026/2499 (81%)\n",
            "\n",
            "Train Epoch: 107 [0/47500 (0%)]\tLoss: 0.384833\n",
            "Train Epoch: 107 [25600/47500 (54%)]\tLoss: 0.455254\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2058/2499 (82%)\n",
            "\n",
            "Train Epoch: 108 [0/47500 (0%)]\tLoss: 0.473054\n",
            "Train Epoch: 108 [25600/47500 (54%)]\tLoss: 0.389640\n",
            "\n",
            "Valid set: Average loss: 0.0094, Accuracy: 2069/2499 (83%)\n",
            "\n",
            "Train Epoch: 109 [0/47500 (0%)]\tLoss: 0.478691\n",
            "Train Epoch: 109 [25600/47500 (54%)]\tLoss: 0.313042\n",
            "\n",
            "Valid set: Average loss: 0.0094, Accuracy: 2075/2499 (83%)\n",
            "\n",
            "Train Epoch: 110 [0/47500 (0%)]\tLoss: 0.357446\n",
            "Train Epoch: 110 [25600/47500 (54%)]\tLoss: 0.379471\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2029/2499 (81%)\n",
            "\n",
            "Train Epoch: 111 [0/47500 (0%)]\tLoss: 0.358258\n",
            "Train Epoch: 111 [25600/47500 (54%)]\tLoss: 0.278682\n",
            "\n",
            "Valid set: Average loss: 0.0097, Accuracy: 2046/2499 (82%)\n",
            "\n",
            "Train Epoch: 112 [0/47500 (0%)]\tLoss: 0.341543\n",
            "Train Epoch: 112 [25600/47500 (54%)]\tLoss: 0.460233\n",
            "\n",
            "Valid set: Average loss: 0.0099, Accuracy: 2056/2499 (82%)\n",
            "\n",
            "Train Epoch: 113 [0/47500 (0%)]\tLoss: 0.324177\n",
            "Train Epoch: 113 [25600/47500 (54%)]\tLoss: 0.355452\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 2034/2499 (81%)\n",
            "\n",
            "Train Epoch: 114 [0/47500 (0%)]\tLoss: 0.428831\n",
            "Train Epoch: 114 [25600/47500 (54%)]\tLoss: 0.383896\n",
            "\n",
            "Valid set: Average loss: 0.0096, Accuracy: 2057/2499 (82%)\n",
            "\n",
            "Train Epoch: 115 [0/47500 (0%)]\tLoss: 0.347058\n",
            "Train Epoch: 115 [25600/47500 (54%)]\tLoss: 0.437001\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2044/2499 (82%)\n",
            "\n",
            "Train Epoch: 116 [0/47500 (0%)]\tLoss: 0.329940\n",
            "Train Epoch: 116 [25600/47500 (54%)]\tLoss: 0.332875\n",
            "\n",
            "Valid set: Average loss: 0.0097, Accuracy: 2072/2499 (83%)\n",
            "\n",
            "Train Epoch: 117 [0/47500 (0%)]\tLoss: 0.424596\n",
            "Train Epoch: 117 [25600/47500 (54%)]\tLoss: 0.474495\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2024/2499 (81%)\n",
            "\n",
            "Train Epoch: 118 [0/47500 (0%)]\tLoss: 0.373752\n",
            "Train Epoch: 118 [25600/47500 (54%)]\tLoss: 0.354647\n",
            "\n",
            "Valid set: Average loss: 0.0099, Accuracy: 2051/2499 (82%)\n",
            "\n",
            "Train Epoch: 119 [0/47500 (0%)]\tLoss: 0.419295\n",
            "Train Epoch: 119 [25600/47500 (54%)]\tLoss: 0.415270\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2036/2499 (81%)\n",
            "\n",
            "Train Epoch: 120 [0/47500 (0%)]\tLoss: 0.451865\n",
            "Train Epoch: 120 [25600/47500 (54%)]\tLoss: 0.353484\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 2044/2499 (82%)\n",
            "\n",
            "Train Epoch: 121 [0/47500 (0%)]\tLoss: 0.423679\n",
            "Train Epoch: 121 [25600/47500 (54%)]\tLoss: 0.431802\n",
            "\n",
            "Valid set: Average loss: 0.0100, Accuracy: 2062/2499 (83%)\n",
            "\n",
            "Train Epoch: 122 [0/47500 (0%)]\tLoss: 0.364543\n",
            "Train Epoch: 122 [25600/47500 (54%)]\tLoss: 0.326359\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 2022/2499 (81%)\n",
            "\n",
            "Train Epoch: 123 [0/47500 (0%)]\tLoss: 0.331543\n",
            "Train Epoch: 123 [25600/47500 (54%)]\tLoss: 0.449731\n",
            "\n",
            "Valid set: Average loss: 0.0113, Accuracy: 2027/2499 (81%)\n",
            "\n",
            "Train Epoch: 124 [0/47500 (0%)]\tLoss: 0.421602\n",
            "Train Epoch: 124 [25600/47500 (54%)]\tLoss: 0.360270\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 2073/2499 (83%)\n",
            "\n",
            "Train Epoch: 125 [0/47500 (0%)]\tLoss: 0.363495\n",
            "Train Epoch: 125 [25600/47500 (54%)]\tLoss: 0.310517\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2037/2499 (82%)\n",
            "\n",
            "Train Epoch: 126 [0/47500 (0%)]\tLoss: 0.454755\n",
            "Train Epoch: 126 [25600/47500 (54%)]\tLoss: 0.355540\n",
            "\n",
            "Valid set: Average loss: 0.0097, Accuracy: 2064/2499 (83%)\n",
            "\n",
            "Train Epoch: 127 [0/47500 (0%)]\tLoss: 0.423535\n",
            "Train Epoch: 127 [25600/47500 (54%)]\tLoss: 0.385223\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 2051/2499 (82%)\n",
            "\n",
            "Train Epoch: 128 [0/47500 (0%)]\tLoss: 0.453653\n",
            "Train Epoch: 128 [25600/47500 (54%)]\tLoss: 0.353955\n",
            "\n",
            "Valid set: Average loss: 0.0094, Accuracy: 2060/2499 (82%)\n",
            "\n",
            "Train Epoch: 129 [0/47500 (0%)]\tLoss: 0.357291\n",
            "Train Epoch: 129 [25600/47500 (54%)]\tLoss: 0.443249\n",
            "\n",
            "Valid set: Average loss: 0.0100, Accuracy: 2063/2499 (83%)\n",
            "\n",
            "Train Epoch: 130 [0/47500 (0%)]\tLoss: 0.356750\n",
            "Train Epoch: 130 [25600/47500 (54%)]\tLoss: 0.318641\n",
            "\n",
            "Valid set: Average loss: 0.0096, Accuracy: 2048/2499 (82%)\n",
            "\n",
            "Train Epoch: 131 [0/47500 (0%)]\tLoss: 0.345059\n",
            "Train Epoch: 131 [25600/47500 (54%)]\tLoss: 0.356722\n",
            "\n",
            "Valid set: Average loss: 0.0100, Accuracy: 2053/2499 (82%)\n",
            "\n",
            "Train Epoch: 132 [0/47500 (0%)]\tLoss: 0.341630\n",
            "Train Epoch: 132 [25600/47500 (54%)]\tLoss: 0.289230\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 2075/2499 (83%)\n",
            "\n",
            "Train Epoch: 133 [0/47500 (0%)]\tLoss: 0.447881\n",
            "Train Epoch: 133 [25600/47500 (54%)]\tLoss: 0.421631\n",
            "\n",
            "Valid set: Average loss: 0.0100, Accuracy: 2037/2499 (82%)\n",
            "\n",
            "Train Epoch: 134 [0/47500 (0%)]\tLoss: 0.325489\n",
            "Train Epoch: 134 [25600/47500 (54%)]\tLoss: 0.292198\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2056/2499 (82%)\n",
            "\n",
            "Train Epoch: 135 [0/47500 (0%)]\tLoss: 0.372573\n",
            "Train Epoch: 135 [25600/47500 (54%)]\tLoss: 0.373384\n",
            "\n",
            "Valid set: Average loss: 0.0098, Accuracy: 2075/2499 (83%)\n",
            "\n",
            "Train Epoch: 136 [0/47500 (0%)]\tLoss: 0.365069\n",
            "Train Epoch: 136 [25600/47500 (54%)]\tLoss: 0.316980\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2061/2499 (82%)\n",
            "\n",
            "Train Epoch: 137 [0/47500 (0%)]\tLoss: 0.328942\n",
            "Train Epoch: 137 [25600/47500 (54%)]\tLoss: 0.333573\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2066/2499 (83%)\n",
            "\n",
            "Train Epoch: 138 [0/47500 (0%)]\tLoss: 0.497556\n",
            "Train Epoch: 138 [25600/47500 (54%)]\tLoss: 0.397381\n",
            "\n",
            "Valid set: Average loss: 0.0096, Accuracy: 2073/2499 (83%)\n",
            "\n",
            "Train Epoch: 139 [0/47500 (0%)]\tLoss: 0.448159\n",
            "Train Epoch: 139 [25600/47500 (54%)]\tLoss: 0.478464\n",
            "\n",
            "Valid set: Average loss: 0.0097, Accuracy: 2081/2499 (83%)\n",
            "\n",
            "Train Epoch: 140 [0/47500 (0%)]\tLoss: 0.491125\n",
            "Train Epoch: 140 [25600/47500 (54%)]\tLoss: 0.340644\n",
            "\n",
            "Valid set: Average loss: 0.0099, Accuracy: 2041/2499 (82%)\n",
            "\n",
            "Train Epoch: 141 [0/47500 (0%)]\tLoss: 0.322350\n",
            "Train Epoch: 141 [25600/47500 (54%)]\tLoss: 0.395664\n",
            "\n",
            "Valid set: Average loss: 0.0100, Accuracy: 2057/2499 (82%)\n",
            "\n",
            "Train Epoch: 142 [0/47500 (0%)]\tLoss: 0.524050\n",
            "Train Epoch: 142 [25600/47500 (54%)]\tLoss: 0.478483\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2046/2499 (82%)\n",
            "\n",
            "Train Epoch: 143 [0/47500 (0%)]\tLoss: 0.365476\n",
            "Train Epoch: 143 [25600/47500 (54%)]\tLoss: 0.415661\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2069/2499 (83%)\n",
            "\n",
            "Train Epoch: 144 [0/47500 (0%)]\tLoss: 0.386931\n",
            "Train Epoch: 144 [25600/47500 (54%)]\tLoss: 0.454360\n",
            "\n",
            "Valid set: Average loss: 0.0096, Accuracy: 2082/2499 (83%)\n",
            "\n",
            "Train Epoch: 145 [0/47500 (0%)]\tLoss: 0.338607\n",
            "Train Epoch: 145 [25600/47500 (54%)]\tLoss: 0.475369\n",
            "\n",
            "Valid set: Average loss: 0.0095, Accuracy: 2050/2499 (82%)\n",
            "\n",
            "Train Epoch: 146 [0/47500 (0%)]\tLoss: 0.360668\n",
            "Train Epoch: 146 [25600/47500 (54%)]\tLoss: 0.312699\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 2070/2499 (83%)\n",
            "\n",
            "Train Epoch: 147 [0/47500 (0%)]\tLoss: 0.394800\n",
            "Train Epoch: 147 [25600/47500 (54%)]\tLoss: 0.369936\n",
            "\n",
            "Valid set: Average loss: 0.0098, Accuracy: 2061/2499 (82%)\n",
            "\n",
            "Train Epoch: 148 [0/47500 (0%)]\tLoss: 0.309958\n",
            "Train Epoch: 148 [25600/47500 (54%)]\tLoss: 0.333585\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2052/2499 (82%)\n",
            "\n",
            "Train Epoch: 149 [0/47500 (0%)]\tLoss: 0.301318\n",
            "Train Epoch: 149 [25600/47500 (54%)]\tLoss: 0.434052\n",
            "\n",
            "Valid set: Average loss: 0.0111, Accuracy: 2046/2499 (82%)\n",
            "\n",
            "Train Epoch: 150 [0/47500 (0%)]\tLoss: 0.377783\n",
            "Train Epoch: 150 [25600/47500 (54%)]\tLoss: 0.359781\n",
            "\n",
            "Valid set: Average loss: 0.0098, Accuracy: 2059/2499 (82%)\n",
            "\n",
            "Train Epoch: 151 [0/47500 (0%)]\tLoss: 0.378856\n",
            "Train Epoch: 151 [25600/47500 (54%)]\tLoss: 0.336855\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2055/2499 (82%)\n",
            "\n",
            "Train Epoch: 152 [0/47500 (0%)]\tLoss: 0.365625\n",
            "Train Epoch: 152 [25600/47500 (54%)]\tLoss: 0.409570\n",
            "\n",
            "Valid set: Average loss: 0.0096, Accuracy: 2042/2499 (82%)\n",
            "\n",
            "Train Epoch: 153 [0/47500 (0%)]\tLoss: 0.393682\n",
            "Train Epoch: 153 [25600/47500 (54%)]\tLoss: 0.356123\n",
            "\n",
            "Valid set: Average loss: 0.0094, Accuracy: 2095/2499 (84%)\n",
            "\n",
            "Train Epoch: 154 [0/47500 (0%)]\tLoss: 0.304672\n",
            "Train Epoch: 154 [25600/47500 (54%)]\tLoss: 0.420877\n",
            "\n",
            "Valid set: Average loss: 0.0112, Accuracy: 2028/2499 (81%)\n",
            "\n",
            "Train Epoch: 155 [0/47500 (0%)]\tLoss: 0.421507\n",
            "Train Epoch: 155 [25600/47500 (54%)]\tLoss: 0.370979\n",
            "\n",
            "Valid set: Average loss: 0.0110, Accuracy: 2033/2499 (81%)\n",
            "\n",
            "Train Epoch: 156 [0/47500 (0%)]\tLoss: 0.372552\n",
            "Train Epoch: 156 [25600/47500 (54%)]\tLoss: 0.256691\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2038/2499 (82%)\n",
            "\n",
            "Train Epoch: 157 [0/47500 (0%)]\tLoss: 0.289107\n",
            "Train Epoch: 157 [25600/47500 (54%)]\tLoss: 0.456425\n",
            "\n",
            "Valid set: Average loss: 0.0118, Accuracy: 2018/2499 (81%)\n",
            "\n",
            "Train Epoch: 158 [0/47500 (0%)]\tLoss: 0.427958\n",
            "Train Epoch: 158 [25600/47500 (54%)]\tLoss: 0.314036\n",
            "\n",
            "Valid set: Average loss: 0.0097, Accuracy: 2079/2499 (83%)\n",
            "\n",
            "Train Epoch: 159 [0/47500 (0%)]\tLoss: 0.315855\n",
            "Train Epoch: 159 [25600/47500 (54%)]\tLoss: 0.435067\n",
            "\n",
            "Valid set: Average loss: 0.0109, Accuracy: 2045/2499 (82%)\n",
            "\n",
            "Train Epoch: 160 [0/47500 (0%)]\tLoss: 0.327070\n",
            "Train Epoch: 160 [25600/47500 (54%)]\tLoss: 0.390394\n",
            "\n",
            "Valid set: Average loss: 0.0109, Accuracy: 2021/2499 (81%)\n",
            "\n",
            "Train Epoch: 161 [0/47500 (0%)]\tLoss: 0.409630\n",
            "Train Epoch: 161 [25600/47500 (54%)]\tLoss: 0.392211\n",
            "\n",
            "Valid set: Average loss: 0.0112, Accuracy: 2041/2499 (82%)\n",
            "\n",
            "Train Epoch: 162 [0/47500 (0%)]\tLoss: 0.425185\n",
            "Train Epoch: 162 [25600/47500 (54%)]\tLoss: 0.325099\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 2071/2499 (83%)\n",
            "\n",
            "Train Epoch: 163 [0/47500 (0%)]\tLoss: 0.418974\n",
            "Train Epoch: 163 [25600/47500 (54%)]\tLoss: 0.366386\n",
            "\n",
            "Valid set: Average loss: 0.0100, Accuracy: 2048/2499 (82%)\n",
            "\n",
            "Train Epoch: 164 [0/47500 (0%)]\tLoss: 0.334793\n",
            "Train Epoch: 164 [25600/47500 (54%)]\tLoss: 0.400693\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2049/2499 (82%)\n",
            "\n",
            "Train Epoch: 165 [0/47500 (0%)]\tLoss: 0.309329\n",
            "Train Epoch: 165 [25600/47500 (54%)]\tLoss: 0.433378\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 2048/2499 (82%)\n",
            "\n",
            "Train Epoch: 166 [0/47500 (0%)]\tLoss: 0.333744\n",
            "Train Epoch: 166 [25600/47500 (54%)]\tLoss: 0.447660\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2035/2499 (81%)\n",
            "\n",
            "Train Epoch: 167 [0/47500 (0%)]\tLoss: 0.493559\n",
            "Train Epoch: 167 [25600/47500 (54%)]\tLoss: 0.371979\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2054/2499 (82%)\n",
            "\n",
            "Train Epoch: 168 [0/47500 (0%)]\tLoss: 0.472214\n",
            "Train Epoch: 168 [25600/47500 (54%)]\tLoss: 0.246551\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 2056/2499 (82%)\n",
            "\n",
            "Train Epoch: 169 [0/47500 (0%)]\tLoss: 0.321595\n",
            "Train Epoch: 169 [25600/47500 (54%)]\tLoss: 0.456288\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 2047/2499 (82%)\n",
            "\n",
            "Train Epoch: 170 [0/47500 (0%)]\tLoss: 0.401315\n",
            "Train Epoch: 170 [25600/47500 (54%)]\tLoss: 0.423438\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2043/2499 (82%)\n",
            "\n",
            "Train Epoch: 171 [0/47500 (0%)]\tLoss: 0.411986\n",
            "Train Epoch: 171 [25600/47500 (54%)]\tLoss: 0.384886\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2067/2499 (83%)\n",
            "\n",
            "Train Epoch: 172 [0/47500 (0%)]\tLoss: 0.406756\n",
            "Train Epoch: 172 [25600/47500 (54%)]\tLoss: 0.295626\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2069/2499 (83%)\n",
            "\n",
            "Train Epoch: 173 [0/47500 (0%)]\tLoss: 0.258288\n",
            "Train Epoch: 173 [25600/47500 (54%)]\tLoss: 0.334631\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2044/2499 (82%)\n",
            "\n",
            "Train Epoch: 174 [0/47500 (0%)]\tLoss: 0.266386\n",
            "Train Epoch: 174 [25600/47500 (54%)]\tLoss: 0.372678\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 2025/2499 (81%)\n",
            "\n",
            "Train Epoch: 175 [0/47500 (0%)]\tLoss: 0.327859\n",
            "Train Epoch: 175 [25600/47500 (54%)]\tLoss: 0.306561\n",
            "\n",
            "Valid set: Average loss: 0.0125, Accuracy: 2041/2499 (82%)\n",
            "\n",
            "Train Epoch: 176 [0/47500 (0%)]\tLoss: 0.364557\n",
            "Train Epoch: 176 [25600/47500 (54%)]\tLoss: 0.292436\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 2042/2499 (82%)\n",
            "\n",
            "Train Epoch: 177 [0/47500 (0%)]\tLoss: 0.296956\n",
            "Train Epoch: 177 [25600/47500 (54%)]\tLoss: 0.312773\n",
            "\n",
            "Valid set: Average loss: 0.0103, Accuracy: 2074/2499 (83%)\n",
            "\n",
            "Train Epoch: 178 [0/47500 (0%)]\tLoss: 0.392538\n",
            "Train Epoch: 178 [25600/47500 (54%)]\tLoss: 0.412732\n",
            "\n",
            "Valid set: Average loss: 0.0095, Accuracy: 2062/2499 (83%)\n",
            "\n",
            "Train Epoch: 179 [0/47500 (0%)]\tLoss: 0.358673\n",
            "Train Epoch: 179 [25600/47500 (54%)]\tLoss: 0.333084\n",
            "\n",
            "Valid set: Average loss: 0.0091, Accuracy: 2082/2499 (83%)\n",
            "\n",
            "Train Epoch: 180 [0/47500 (0%)]\tLoss: 0.361825\n",
            "Train Epoch: 180 [25600/47500 (54%)]\tLoss: 0.372873\n",
            "\n",
            "Valid set: Average loss: 0.0117, Accuracy: 2065/2499 (83%)\n",
            "\n",
            "Train Epoch: 181 [0/47500 (0%)]\tLoss: 0.302380\n",
            "Train Epoch: 181 [25600/47500 (54%)]\tLoss: 0.471674\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2055/2499 (82%)\n",
            "\n",
            "Train Epoch: 182 [0/47500 (0%)]\tLoss: 0.331445\n",
            "Train Epoch: 182 [25600/47500 (54%)]\tLoss: 0.405264\n",
            "\n",
            "Valid set: Average loss: 0.0106, Accuracy: 2063/2499 (83%)\n",
            "\n",
            "Train Epoch: 183 [0/47500 (0%)]\tLoss: 0.489822\n",
            "Train Epoch: 183 [25600/47500 (54%)]\tLoss: 0.442968\n",
            "\n",
            "Valid set: Average loss: 0.0109, Accuracy: 2030/2499 (81%)\n",
            "\n",
            "Train Epoch: 184 [0/47500 (0%)]\tLoss: 0.335827\n",
            "Train Epoch: 184 [25600/47500 (54%)]\tLoss: 0.316833\n",
            "\n",
            "Valid set: Average loss: 0.0099, Accuracy: 2084/2499 (83%)\n",
            "\n",
            "Train Epoch: 185 [0/47500 (0%)]\tLoss: 0.387707\n",
            "Train Epoch: 185 [25600/47500 (54%)]\tLoss: 0.329491\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 2048/2499 (82%)\n",
            "\n",
            "Train Epoch: 186 [0/47500 (0%)]\tLoss: 0.303687\n",
            "Train Epoch: 186 [25600/47500 (54%)]\tLoss: 0.308656\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2065/2499 (83%)\n",
            "\n",
            "Train Epoch: 187 [0/47500 (0%)]\tLoss: 0.435990\n",
            "Train Epoch: 187 [25600/47500 (54%)]\tLoss: 0.509028\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 2060/2499 (82%)\n",
            "\n",
            "Train Epoch: 188 [0/47500 (0%)]\tLoss: 0.425072\n",
            "Train Epoch: 188 [25600/47500 (54%)]\tLoss: 0.324771\n",
            "\n",
            "Valid set: Average loss: 0.0111, Accuracy: 2030/2499 (81%)\n",
            "\n",
            "Train Epoch: 189 [0/47500 (0%)]\tLoss: 0.274943\n",
            "Train Epoch: 189 [25600/47500 (54%)]\tLoss: 0.334938\n",
            "\n",
            "Valid set: Average loss: 0.0100, Accuracy: 2069/2499 (83%)\n",
            "\n",
            "Train Epoch: 190 [0/47500 (0%)]\tLoss: 0.273773\n",
            "Train Epoch: 190 [25600/47500 (54%)]\tLoss: 0.366685\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 2048/2499 (82%)\n",
            "\n",
            "Train Epoch: 191 [0/47500 (0%)]\tLoss: 0.262377\n",
            "Train Epoch: 191 [25600/47500 (54%)]\tLoss: 0.406098\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 2080/2499 (83%)\n",
            "\n",
            "Train Epoch: 192 [0/47500 (0%)]\tLoss: 0.358620\n",
            "Train Epoch: 192 [25600/47500 (54%)]\tLoss: 0.374386\n",
            "\n",
            "Valid set: Average loss: 0.0133, Accuracy: 2025/2499 (81%)\n",
            "\n",
            "Train Epoch: 193 [0/47500 (0%)]\tLoss: 0.293969\n",
            "Train Epoch: 193 [25600/47500 (54%)]\tLoss: 0.292339\n",
            "\n",
            "Valid set: Average loss: 0.0112, Accuracy: 2028/2499 (81%)\n",
            "\n",
            "Train Epoch: 194 [0/47500 (0%)]\tLoss: 0.365351\n",
            "Train Epoch: 194 [25600/47500 (54%)]\tLoss: 0.382468\n",
            "\n",
            "Valid set: Average loss: 0.0125, Accuracy: 2022/2499 (81%)\n",
            "\n",
            "Train Epoch: 195 [0/47500 (0%)]\tLoss: 0.397906\n",
            "Train Epoch: 195 [25600/47500 (54%)]\tLoss: 0.304173\n",
            "\n",
            "Valid set: Average loss: 0.0121, Accuracy: 2034/2499 (81%)\n",
            "\n",
            "Train Epoch: 196 [0/47500 (0%)]\tLoss: 0.279578\n",
            "Train Epoch: 196 [25600/47500 (54%)]\tLoss: 0.495333\n",
            "\n",
            "Valid set: Average loss: 0.0098, Accuracy: 2064/2499 (83%)\n",
            "\n",
            "Train Epoch: 197 [0/47500 (0%)]\tLoss: 0.353613\n",
            "Train Epoch: 197 [25600/47500 (54%)]\tLoss: 0.356419\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 2035/2499 (81%)\n",
            "\n",
            "Train Epoch: 198 [0/47500 (0%)]\tLoss: 0.391519\n",
            "Train Epoch: 198 [25600/47500 (54%)]\tLoss: 0.366963\n",
            "\n",
            "Valid set: Average loss: 0.0109, Accuracy: 2048/2499 (82%)\n",
            "\n",
            "Train Epoch: 199 [0/47500 (0%)]\tLoss: 0.370252\n",
            "Train Epoch: 199 [25600/47500 (54%)]\tLoss: 0.226014\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 2074/2499 (83%)\n",
            "\n",
            "Train Epoch: 200 [0/47500 (0%)]\tLoss: 0.408796\n",
            "Train Epoch: 200 [25600/47500 (54%)]\tLoss: 0.291067\n",
            "\n",
            "Valid set: Average loss: 0.0103, Accuracy: 2082/2499 (83%)\n",
            "\n",
            "Train Epoch: 201 [0/47500 (0%)]\tLoss: 0.373537\n",
            "Train Epoch: 201 [25600/47500 (54%)]\tLoss: 0.274135\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 2063/2499 (83%)\n",
            "\n",
            "Train Epoch: 202 [0/47500 (0%)]\tLoss: 0.309238\n",
            "Train Epoch: 202 [25600/47500 (54%)]\tLoss: 0.268863\n",
            "\n",
            "Valid set: Average loss: 0.0100, Accuracy: 2084/2499 (83%)\n",
            "\n",
            "Train Epoch: 203 [0/47500 (0%)]\tLoss: 0.315978\n",
            "Train Epoch: 203 [25600/47500 (54%)]\tLoss: 0.333284\n",
            "\n",
            "Valid set: Average loss: 0.0110, Accuracy: 2062/2499 (83%)\n",
            "\n",
            "Train Epoch: 204 [0/47500 (0%)]\tLoss: 0.278841\n",
            "Train Epoch: 204 [25600/47500 (54%)]\tLoss: 0.251908\n",
            "\n",
            "Valid set: Average loss: 0.0109, Accuracy: 2049/2499 (82%)\n",
            "\n",
            "Train Epoch: 205 [0/47500 (0%)]\tLoss: 0.210886\n",
            "Train Epoch: 205 [25600/47500 (54%)]\tLoss: 0.254978\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2076/2499 (83%)\n",
            "\n",
            "Train Epoch: 206 [0/47500 (0%)]\tLoss: 0.321070\n",
            "Train Epoch: 206 [25600/47500 (54%)]\tLoss: 0.266045\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 2073/2499 (83%)\n",
            "\n",
            "Train Epoch: 207 [0/47500 (0%)]\tLoss: 0.241657\n",
            "Train Epoch: 207 [25600/47500 (54%)]\tLoss: 0.261546\n",
            "\n",
            "Valid set: Average loss: 0.0106, Accuracy: 2094/2499 (84%)\n",
            "\n",
            "Train Epoch: 208 [0/47500 (0%)]\tLoss: 0.338320\n",
            "Train Epoch: 208 [25600/47500 (54%)]\tLoss: 0.282561\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 2087/2499 (84%)\n",
            "\n",
            "Train Epoch: 209 [0/47500 (0%)]\tLoss: 0.254954\n",
            "Train Epoch: 209 [25600/47500 (54%)]\tLoss: 0.295015\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2084/2499 (83%)\n",
            "\n",
            "Train Epoch: 210 [0/47500 (0%)]\tLoss: 0.259937\n",
            "Train Epoch: 210 [25600/47500 (54%)]\tLoss: 0.277816\n",
            "\n",
            "Valid set: Average loss: 0.0111, Accuracy: 2096/2499 (84%)\n",
            "\n",
            "Train Epoch: 211 [0/47500 (0%)]\tLoss: 0.227052\n",
            "Train Epoch: 211 [25600/47500 (54%)]\tLoss: 0.290596\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 2072/2499 (83%)\n",
            "\n",
            "Train Epoch: 212 [0/47500 (0%)]\tLoss: 0.262491\n",
            "Train Epoch: 212 [25600/47500 (54%)]\tLoss: 0.250280\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2095/2499 (84%)\n",
            "\n",
            "Train Epoch: 213 [0/47500 (0%)]\tLoss: 0.294788\n",
            "Train Epoch: 213 [25600/47500 (54%)]\tLoss: 0.181686\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2103/2499 (84%)\n",
            "\n",
            "Train Epoch: 214 [0/47500 (0%)]\tLoss: 0.256072\n",
            "Train Epoch: 214 [25600/47500 (54%)]\tLoss: 0.242718\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 2074/2499 (83%)\n",
            "\n",
            "Train Epoch: 215 [0/47500 (0%)]\tLoss: 0.299113\n",
            "Train Epoch: 215 [25600/47500 (54%)]\tLoss: 0.241191\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 2081/2499 (83%)\n",
            "\n",
            "Train Epoch: 216 [0/47500 (0%)]\tLoss: 0.197027\n",
            "Train Epoch: 216 [25600/47500 (54%)]\tLoss: 0.304056\n",
            "\n",
            "Valid set: Average loss: 0.0103, Accuracy: 2088/2499 (84%)\n",
            "\n",
            "Train Epoch: 217 [0/47500 (0%)]\tLoss: 0.371938\n",
            "Train Epoch: 217 [25600/47500 (54%)]\tLoss: 0.222799\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 2093/2499 (84%)\n",
            "\n",
            "Train Epoch: 218 [0/47500 (0%)]\tLoss: 0.291924\n",
            "Train Epoch: 218 [25600/47500 (54%)]\tLoss: 0.192955\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2075/2499 (83%)\n",
            "\n",
            "Train Epoch: 219 [0/47500 (0%)]\tLoss: 0.198949\n",
            "Train Epoch: 219 [25600/47500 (54%)]\tLoss: 0.275772\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2096/2499 (84%)\n",
            "\n",
            "Train Epoch: 220 [0/47500 (0%)]\tLoss: 0.236023\n",
            "Train Epoch: 220 [25600/47500 (54%)]\tLoss: 0.198815\n",
            "\n",
            "Valid set: Average loss: 0.0111, Accuracy: 2095/2499 (84%)\n",
            "\n",
            "Train Epoch: 221 [0/47500 (0%)]\tLoss: 0.224178\n",
            "Train Epoch: 221 [25600/47500 (54%)]\tLoss: 0.266192\n",
            "\n",
            "Valid set: Average loss: 0.0118, Accuracy: 2050/2499 (82%)\n",
            "\n",
            "Train Epoch: 222 [0/47500 (0%)]\tLoss: 0.289650\n",
            "Train Epoch: 222 [25600/47500 (54%)]\tLoss: 0.255259\n",
            "\n",
            "Valid set: Average loss: 0.0106, Accuracy: 2079/2499 (83%)\n",
            "\n",
            "Train Epoch: 223 [0/47500 (0%)]\tLoss: 0.277325\n",
            "Train Epoch: 223 [25600/47500 (54%)]\tLoss: 0.155358\n",
            "\n",
            "Valid set: Average loss: 0.0109, Accuracy: 2078/2499 (83%)\n",
            "\n",
            "Train Epoch: 224 [0/47500 (0%)]\tLoss: 0.205754\n",
            "Train Epoch: 224 [25600/47500 (54%)]\tLoss: 0.307681\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2091/2499 (84%)\n",
            "\n",
            "Train Epoch: 225 [0/47500 (0%)]\tLoss: 0.268338\n",
            "Train Epoch: 225 [25600/47500 (54%)]\tLoss: 0.234244\n",
            "\n",
            "Valid set: Average loss: 0.0111, Accuracy: 2088/2499 (84%)\n",
            "\n",
            "Train Epoch: 226 [0/47500 (0%)]\tLoss: 0.263925\n",
            "Train Epoch: 226 [25600/47500 (54%)]\tLoss: 0.239442\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 2081/2499 (83%)\n",
            "\n",
            "Train Epoch: 227 [0/47500 (0%)]\tLoss: 0.264940\n",
            "Train Epoch: 227 [25600/47500 (54%)]\tLoss: 0.180338\n",
            "\n",
            "Valid set: Average loss: 0.0110, Accuracy: 2078/2499 (83%)\n",
            "\n",
            "Train Epoch: 228 [0/47500 (0%)]\tLoss: 0.345227\n",
            "Train Epoch: 228 [25600/47500 (54%)]\tLoss: 0.192954\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 2081/2499 (83%)\n",
            "\n",
            "Train Epoch: 229 [0/47500 (0%)]\tLoss: 0.272481\n",
            "Train Epoch: 229 [25600/47500 (54%)]\tLoss: 0.175524\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2075/2499 (83%)\n",
            "\n",
            "Train Epoch: 230 [0/47500 (0%)]\tLoss: 0.340207\n",
            "Train Epoch: 230 [25600/47500 (54%)]\tLoss: 0.225224\n",
            "\n",
            "Valid set: Average loss: 0.0100, Accuracy: 2101/2499 (84%)\n",
            "\n",
            "Train Epoch: 231 [0/47500 (0%)]\tLoss: 0.215790\n",
            "Train Epoch: 231 [25600/47500 (54%)]\tLoss: 0.224356\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2091/2499 (84%)\n",
            "\n",
            "Train Epoch: 232 [0/47500 (0%)]\tLoss: 0.239171\n",
            "Train Epoch: 232 [25600/47500 (54%)]\tLoss: 0.206167\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 2072/2499 (83%)\n",
            "\n",
            "Train Epoch: 233 [0/47500 (0%)]\tLoss: 0.247298\n",
            "Train Epoch: 233 [25600/47500 (54%)]\tLoss: 0.298836\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2081/2499 (83%)\n",
            "\n",
            "Train Epoch: 234 [0/47500 (0%)]\tLoss: 0.267832\n",
            "Train Epoch: 234 [25600/47500 (54%)]\tLoss: 0.234986\n",
            "\n",
            "Valid set: Average loss: 0.0106, Accuracy: 2096/2499 (84%)\n",
            "\n",
            "Train Epoch: 235 [0/47500 (0%)]\tLoss: 0.211466\n",
            "Train Epoch: 235 [25600/47500 (54%)]\tLoss: 0.247651\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2088/2499 (84%)\n",
            "\n",
            "Train Epoch: 236 [0/47500 (0%)]\tLoss: 0.272362\n",
            "Train Epoch: 236 [25600/47500 (54%)]\tLoss: 0.282651\n",
            "\n",
            "Valid set: Average loss: 0.0110, Accuracy: 2091/2499 (84%)\n",
            "\n",
            "Train Epoch: 237 [0/47500 (0%)]\tLoss: 0.220621\n",
            "Train Epoch: 237 [25600/47500 (54%)]\tLoss: 0.242184\n",
            "\n",
            "Valid set: Average loss: 0.0106, Accuracy: 2070/2499 (83%)\n",
            "\n",
            "Train Epoch: 238 [0/47500 (0%)]\tLoss: 0.279663\n",
            "Train Epoch: 238 [25600/47500 (54%)]\tLoss: 0.195603\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 2085/2499 (83%)\n",
            "\n",
            "Train Epoch: 239 [0/47500 (0%)]\tLoss: 0.180394\n",
            "Train Epoch: 239 [25600/47500 (54%)]\tLoss: 0.295262\n",
            "\n",
            "Valid set: Average loss: 0.0109, Accuracy: 2078/2499 (83%)\n",
            "\n",
            "Train Epoch: 240 [0/47500 (0%)]\tLoss: 0.191043\n",
            "Train Epoch: 240 [25600/47500 (54%)]\tLoss: 0.170444\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2089/2499 (84%)\n",
            "\n",
            "Train Epoch: 241 [0/47500 (0%)]\tLoss: 0.232837\n",
            "Train Epoch: 241 [25600/47500 (54%)]\tLoss: 0.268394\n",
            "\n",
            "Valid set: Average loss: 0.0103, Accuracy: 2072/2499 (83%)\n",
            "\n",
            "Train Epoch: 242 [0/47500 (0%)]\tLoss: 0.275967\n",
            "Train Epoch: 242 [25600/47500 (54%)]\tLoss: 0.183806\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2115/2499 (85%)\n",
            "\n",
            "Train Epoch: 243 [0/47500 (0%)]\tLoss: 0.212103\n",
            "Train Epoch: 243 [25600/47500 (54%)]\tLoss: 0.256543\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2087/2499 (84%)\n",
            "\n",
            "Train Epoch: 244 [0/47500 (0%)]\tLoss: 0.270051\n",
            "Train Epoch: 244 [25600/47500 (54%)]\tLoss: 0.328649\n",
            "\n",
            "Valid set: Average loss: 0.0112, Accuracy: 2060/2499 (82%)\n",
            "\n",
            "Train Epoch: 245 [0/47500 (0%)]\tLoss: 0.316070\n",
            "Train Epoch: 245 [25600/47500 (54%)]\tLoss: 0.216836\n",
            "\n",
            "Valid set: Average loss: 0.0098, Accuracy: 2095/2499 (84%)\n",
            "\n",
            "Train Epoch: 246 [0/47500 (0%)]\tLoss: 0.294311\n",
            "Train Epoch: 246 [25600/47500 (54%)]\tLoss: 0.280181\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 2096/2499 (84%)\n",
            "\n",
            "Train Epoch: 247 [0/47500 (0%)]\tLoss: 0.315476\n",
            "Train Epoch: 247 [25600/47500 (54%)]\tLoss: 0.207575\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 2088/2499 (84%)\n",
            "\n",
            "Train Epoch: 248 [0/47500 (0%)]\tLoss: 0.252160\n",
            "Train Epoch: 248 [25600/47500 (54%)]\tLoss: 0.185348\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2109/2499 (84%)\n",
            "\n",
            "Train Epoch: 249 [0/47500 (0%)]\tLoss: 0.214844\n",
            "Train Epoch: 249 [25600/47500 (54%)]\tLoss: 0.180658\n",
            "\n",
            "Valid set: Average loss: 0.0109, Accuracy: 2087/2499 (84%)\n",
            "\n",
            "Train Epoch: 250 [0/47500 (0%)]\tLoss: 0.338145\n",
            "Train Epoch: 250 [25600/47500 (54%)]\tLoss: 0.204084\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2093/2499 (84%)\n",
            "\n",
            "Train Epoch: 251 [0/47500 (0%)]\tLoss: 0.191073\n",
            "Train Epoch: 251 [25600/47500 (54%)]\tLoss: 0.238639\n",
            "\n",
            "Valid set: Average loss: 0.0109, Accuracy: 2093/2499 (84%)\n",
            "\n",
            "Train Epoch: 252 [0/47500 (0%)]\tLoss: 0.229979\n",
            "Train Epoch: 252 [25600/47500 (54%)]\tLoss: 0.228445\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2089/2499 (84%)\n",
            "\n",
            "Train Epoch: 253 [0/47500 (0%)]\tLoss: 0.253309\n",
            "Train Epoch: 253 [25600/47500 (54%)]\tLoss: 0.233743\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2106/2499 (84%)\n",
            "\n",
            "Train Epoch: 254 [0/47500 (0%)]\tLoss: 0.296068\n",
            "Train Epoch: 254 [25600/47500 (54%)]\tLoss: 0.212538\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 2089/2499 (84%)\n",
            "\n",
            "Train Epoch: 255 [0/47500 (0%)]\tLoss: 0.239718\n",
            "Train Epoch: 255 [25600/47500 (54%)]\tLoss: 0.235972\n",
            "\n",
            "Valid set: Average loss: 0.0109, Accuracy: 2094/2499 (84%)\n",
            "\n",
            "Train Epoch: 256 [0/47500 (0%)]\tLoss: 0.249989\n",
            "Train Epoch: 256 [25600/47500 (54%)]\tLoss: 0.232357\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2105/2499 (84%)\n",
            "\n",
            "Train Epoch: 257 [0/47500 (0%)]\tLoss: 0.268930\n",
            "Train Epoch: 257 [25600/47500 (54%)]\tLoss: 0.229945\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 2083/2499 (83%)\n",
            "\n",
            "Train Epoch: 258 [0/47500 (0%)]\tLoss: 0.223352\n",
            "Train Epoch: 258 [25600/47500 (54%)]\tLoss: 0.309888\n",
            "\n",
            "Valid set: Average loss: 0.0099, Accuracy: 2102/2499 (84%)\n",
            "\n",
            "Train Epoch: 259 [0/47500 (0%)]\tLoss: 0.217121\n",
            "Train Epoch: 259 [25600/47500 (54%)]\tLoss: 0.371331\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2078/2499 (83%)\n",
            "\n",
            "Train Epoch: 260 [0/47500 (0%)]\tLoss: 0.123771\n",
            "Train Epoch: 260 [25600/47500 (54%)]\tLoss: 0.174996\n",
            "\n",
            "Valid set: Average loss: 0.0110, Accuracy: 2088/2499 (84%)\n",
            "\n",
            "Train Epoch: 261 [0/47500 (0%)]\tLoss: 0.169621\n",
            "Train Epoch: 261 [25600/47500 (54%)]\tLoss: 0.268271\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2101/2499 (84%)\n",
            "\n",
            "Train Epoch: 262 [0/47500 (0%)]\tLoss: 0.260518\n",
            "Train Epoch: 262 [25600/47500 (54%)]\tLoss: 0.260417\n",
            "\n",
            "Valid set: Average loss: 0.0106, Accuracy: 2095/2499 (84%)\n",
            "\n",
            "Train Epoch: 263 [0/47500 (0%)]\tLoss: 0.243727\n",
            "Train Epoch: 263 [25600/47500 (54%)]\tLoss: 0.262246\n",
            "\n",
            "Valid set: Average loss: 0.0111, Accuracy: 2087/2499 (84%)\n",
            "\n",
            "Train Epoch: 264 [0/47500 (0%)]\tLoss: 0.231157\n",
            "Train Epoch: 264 [25600/47500 (54%)]\tLoss: 0.246644\n",
            "\n",
            "Valid set: Average loss: 0.0109, Accuracy: 2093/2499 (84%)\n",
            "\n",
            "Train Epoch: 265 [0/47500 (0%)]\tLoss: 0.256755\n",
            "Train Epoch: 265 [25600/47500 (54%)]\tLoss: 0.161109\n",
            "\n",
            "Valid set: Average loss: 0.0111, Accuracy: 2096/2499 (84%)\n",
            "\n",
            "Train Epoch: 266 [0/47500 (0%)]\tLoss: 0.213114\n",
            "Train Epoch: 266 [25600/47500 (54%)]\tLoss: 0.169330\n",
            "\n",
            "Valid set: Average loss: 0.0109, Accuracy: 2070/2499 (83%)\n",
            "\n",
            "Train Epoch: 267 [0/47500 (0%)]\tLoss: 0.245752\n",
            "Train Epoch: 267 [25600/47500 (54%)]\tLoss: 0.333006\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 2104/2499 (84%)\n",
            "\n",
            "Train Epoch: 268 [0/47500 (0%)]\tLoss: 0.222172\n",
            "Train Epoch: 268 [25600/47500 (54%)]\tLoss: 0.243174\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2099/2499 (84%)\n",
            "\n",
            "Train Epoch: 269 [0/47500 (0%)]\tLoss: 0.217184\n",
            "Train Epoch: 269 [25600/47500 (54%)]\tLoss: 0.161163\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2085/2499 (83%)\n",
            "\n",
            "Train Epoch: 270 [0/47500 (0%)]\tLoss: 0.293186\n",
            "Train Epoch: 270 [25600/47500 (54%)]\tLoss: 0.176856\n",
            "\n",
            "Valid set: Average loss: 0.0106, Accuracy: 2095/2499 (84%)\n",
            "\n",
            "Train Epoch: 271 [0/47500 (0%)]\tLoss: 0.252333\n",
            "Train Epoch: 271 [25600/47500 (54%)]\tLoss: 0.235544\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2080/2499 (83%)\n",
            "\n",
            "Train Epoch: 272 [0/47500 (0%)]\tLoss: 0.224938\n",
            "Train Epoch: 272 [25600/47500 (54%)]\tLoss: 0.350817\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2099/2499 (84%)\n",
            "\n",
            "Train Epoch: 273 [0/47500 (0%)]\tLoss: 0.262827\n",
            "Train Epoch: 273 [25600/47500 (54%)]\tLoss: 0.166840\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 2099/2499 (84%)\n",
            "\n",
            "Train Epoch: 274 [0/47500 (0%)]\tLoss: 0.223002\n",
            "Train Epoch: 274 [25600/47500 (54%)]\tLoss: 0.248332\n",
            "\n",
            "Valid set: Average loss: 0.0113, Accuracy: 2073/2499 (83%)\n",
            "\n",
            "Train Epoch: 275 [0/47500 (0%)]\tLoss: 0.319109\n",
            "Train Epoch: 275 [25600/47500 (54%)]\tLoss: 0.171661\n",
            "\n",
            "Valid set: Average loss: 0.0110, Accuracy: 2075/2499 (83%)\n",
            "\n",
            "Train Epoch: 276 [0/47500 (0%)]\tLoss: 0.168251\n",
            "Train Epoch: 276 [25600/47500 (54%)]\tLoss: 0.220468\n",
            "\n",
            "Valid set: Average loss: 0.0115, Accuracy: 2093/2499 (84%)\n",
            "\n",
            "Train Epoch: 277 [0/47500 (0%)]\tLoss: 0.245006\n",
            "Train Epoch: 277 [25600/47500 (54%)]\tLoss: 0.214021\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 2094/2499 (84%)\n",
            "\n",
            "Train Epoch: 278 [0/47500 (0%)]\tLoss: 0.166218\n",
            "Train Epoch: 278 [25600/47500 (54%)]\tLoss: 0.246369\n",
            "\n",
            "Valid set: Average loss: 0.0111, Accuracy: 2086/2499 (83%)\n",
            "\n",
            "Train Epoch: 279 [0/47500 (0%)]\tLoss: 0.275373\n",
            "Train Epoch: 279 [25600/47500 (54%)]\tLoss: 0.186565\n",
            "\n",
            "Valid set: Average loss: 0.0106, Accuracy: 2101/2499 (84%)\n",
            "\n",
            "Train Epoch: 280 [0/47500 (0%)]\tLoss: 0.140788\n",
            "Train Epoch: 280 [25600/47500 (54%)]\tLoss: 0.195746\n",
            "\n",
            "Valid set: Average loss: 0.0097, Accuracy: 2108/2499 (84%)\n",
            "\n",
            "Train Epoch: 281 [0/47500 (0%)]\tLoss: 0.221580\n",
            "Train Epoch: 281 [25600/47500 (54%)]\tLoss: 0.165167\n",
            "\n",
            "Valid set: Average loss: 0.0106, Accuracy: 2069/2499 (83%)\n",
            "\n",
            "Train Epoch: 282 [0/47500 (0%)]\tLoss: 0.210209\n",
            "Train Epoch: 282 [25600/47500 (54%)]\tLoss: 0.194610\n",
            "\n",
            "Valid set: Average loss: 0.0100, Accuracy: 2117/2499 (85%)\n",
            "\n",
            "Train Epoch: 283 [0/47500 (0%)]\tLoss: 0.294467\n",
            "Train Epoch: 283 [25600/47500 (54%)]\tLoss: 0.252754\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 2088/2499 (84%)\n",
            "\n",
            "Train Epoch: 284 [0/47500 (0%)]\tLoss: 0.228746\n",
            "Train Epoch: 284 [25600/47500 (54%)]\tLoss: 0.234594\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2073/2499 (83%)\n",
            "\n",
            "Train Epoch: 285 [0/47500 (0%)]\tLoss: 0.232389\n",
            "Train Epoch: 285 [25600/47500 (54%)]\tLoss: 0.152874\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2110/2499 (84%)\n",
            "\n",
            "Train Epoch: 286 [0/47500 (0%)]\tLoss: 0.199586\n",
            "Train Epoch: 286 [25600/47500 (54%)]\tLoss: 0.256269\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 2099/2499 (84%)\n",
            "\n",
            "Train Epoch: 287 [0/47500 (0%)]\tLoss: 0.272000\n",
            "Train Epoch: 287 [25600/47500 (54%)]\tLoss: 0.214229\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2106/2499 (84%)\n",
            "\n",
            "Train Epoch: 288 [0/47500 (0%)]\tLoss: 0.300118\n",
            "Train Epoch: 288 [25600/47500 (54%)]\tLoss: 0.289302\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2101/2499 (84%)\n",
            "\n",
            "Train Epoch: 289 [0/47500 (0%)]\tLoss: 0.219666\n",
            "Train Epoch: 289 [25600/47500 (54%)]\tLoss: 0.321979\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2103/2499 (84%)\n",
            "\n",
            "Train Epoch: 290 [0/47500 (0%)]\tLoss: 0.221840\n",
            "Train Epoch: 290 [25600/47500 (54%)]\tLoss: 0.283974\n",
            "\n",
            "Valid set: Average loss: 0.0110, Accuracy: 2086/2499 (83%)\n",
            "\n",
            "Train Epoch: 291 [0/47500 (0%)]\tLoss: 0.234205\n",
            "Train Epoch: 291 [25600/47500 (54%)]\tLoss: 0.234831\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2098/2499 (84%)\n",
            "\n",
            "Train Epoch: 292 [0/47500 (0%)]\tLoss: 0.283710\n",
            "Train Epoch: 292 [25600/47500 (54%)]\tLoss: 0.226132\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2092/2499 (84%)\n",
            "\n",
            "Train Epoch: 293 [0/47500 (0%)]\tLoss: 0.259600\n",
            "Train Epoch: 293 [25600/47500 (54%)]\tLoss: 0.200398\n",
            "\n",
            "Valid set: Average loss: 0.0106, Accuracy: 2092/2499 (84%)\n",
            "\n",
            "Train Epoch: 294 [0/47500 (0%)]\tLoss: 0.391459\n",
            "Train Epoch: 294 [25600/47500 (54%)]\tLoss: 0.244553\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2091/2499 (84%)\n",
            "\n",
            "Train Epoch: 295 [0/47500 (0%)]\tLoss: 0.223568\n",
            "Train Epoch: 295 [25600/47500 (54%)]\tLoss: 0.216626\n",
            "\n",
            "Valid set: Average loss: 0.0106, Accuracy: 2113/2499 (85%)\n",
            "\n",
            "Train Epoch: 296 [0/47500 (0%)]\tLoss: 0.251809\n",
            "Train Epoch: 296 [25600/47500 (54%)]\tLoss: 0.286670\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 2084/2499 (83%)\n",
            "\n",
            "Train Epoch: 297 [0/47500 (0%)]\tLoss: 0.232108\n",
            "Train Epoch: 297 [25600/47500 (54%)]\tLoss: 0.220215\n",
            "\n",
            "Valid set: Average loss: 0.0106, Accuracy: 2086/2499 (83%)\n",
            "\n",
            "Train Epoch: 298 [0/47500 (0%)]\tLoss: 0.169864\n",
            "Train Epoch: 298 [25600/47500 (54%)]\tLoss: 0.259042\n",
            "\n",
            "Valid set: Average loss: 0.0106, Accuracy: 2096/2499 (84%)\n",
            "\n",
            "Train Epoch: 299 [0/47500 (0%)]\tLoss: 0.290363\n",
            "Train Epoch: 299 [25600/47500 (54%)]\tLoss: 0.188856\n",
            "\n",
            "Valid set: Average loss: 0.0111, Accuracy: 2094/2499 (84%)\n",
            "\n",
            "Train Epoch: 300 [0/47500 (0%)]\tLoss: 0.192571\n",
            "Train Epoch: 300 [25600/47500 (54%)]\tLoss: 0.295141\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2104/2499 (84%)\n",
            "\n",
            "Train Epoch: 301 [0/47500 (0%)]\tLoss: 0.378652\n",
            "Train Epoch: 301 [25600/47500 (54%)]\tLoss: 0.301244\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 2090/2499 (84%)\n",
            "\n",
            "Train Epoch: 302 [0/47500 (0%)]\tLoss: 0.310390\n",
            "Train Epoch: 302 [25600/47500 (54%)]\tLoss: 0.229801\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 2079/2499 (83%)\n",
            "\n",
            "Train Epoch: 303 [0/47500 (0%)]\tLoss: 0.239199\n",
            "Train Epoch: 303 [25600/47500 (54%)]\tLoss: 0.212944\n",
            "\n",
            "Valid set: Average loss: 0.0103, Accuracy: 2098/2499 (84%)\n",
            "\n",
            "Train Epoch: 304 [0/47500 (0%)]\tLoss: 0.245723\n",
            "Train Epoch: 304 [25600/47500 (54%)]\tLoss: 0.250083\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 2091/2499 (84%)\n",
            "\n",
            "Train Epoch: 305 [0/47500 (0%)]\tLoss: 0.281310\n",
            "Train Epoch: 305 [25600/47500 (54%)]\tLoss: 0.179160\n",
            "\n",
            "Valid set: Average loss: 0.0109, Accuracy: 2086/2499 (83%)\n",
            "\n",
            "Train Epoch: 306 [0/47500 (0%)]\tLoss: 0.181413\n",
            "Train Epoch: 306 [25600/47500 (54%)]\tLoss: 0.179295\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 2089/2499 (84%)\n",
            "\n",
            "Train Epoch: 307 [0/47500 (0%)]\tLoss: 0.177511\n",
            "Train Epoch: 307 [25600/47500 (54%)]\tLoss: 0.211455\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 2091/2499 (84%)\n",
            "\n",
            "Train Epoch: 308 [0/47500 (0%)]\tLoss: 0.180771\n",
            "Train Epoch: 308 [25600/47500 (54%)]\tLoss: 0.150567\n",
            "\n",
            "Valid set: Average loss: 0.0111, Accuracy: 2094/2499 (84%)\n",
            "\n",
            "Train Epoch: 309 [0/47500 (0%)]\tLoss: 0.192710\n",
            "Train Epoch: 309 [25600/47500 (54%)]\tLoss: 0.234501\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2113/2499 (85%)\n",
            "\n",
            "Train Epoch: 310 [0/47500 (0%)]\tLoss: 0.252215\n",
            "Train Epoch: 310 [25600/47500 (54%)]\tLoss: 0.197236\n",
            "\n",
            "Valid set: Average loss: 0.0101, Accuracy: 2124/2499 (85%)\n",
            "\n",
            "Train Epoch: 311 [0/47500 (0%)]\tLoss: 0.253797\n",
            "Train Epoch: 311 [25600/47500 (54%)]\tLoss: 0.196730\n",
            "\n",
            "Valid set: Average loss: 0.0103, Accuracy: 2102/2499 (84%)\n",
            "\n",
            "Train Epoch: 312 [0/47500 (0%)]\tLoss: 0.297164\n",
            "Train Epoch: 312 [25600/47500 (54%)]\tLoss: 0.236015\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2087/2499 (84%)\n",
            "\n",
            "Train Epoch: 313 [0/47500 (0%)]\tLoss: 0.245018\n",
            "Train Epoch: 313 [25600/47500 (54%)]\tLoss: 0.293014\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2086/2499 (83%)\n",
            "\n",
            "Train Epoch: 314 [0/47500 (0%)]\tLoss: 0.197123\n",
            "Train Epoch: 314 [25600/47500 (54%)]\tLoss: 0.205426\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2095/2499 (84%)\n",
            "\n",
            "Train Epoch: 315 [0/47500 (0%)]\tLoss: 0.278958\n",
            "Train Epoch: 315 [25600/47500 (54%)]\tLoss: 0.290382\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 2090/2499 (84%)\n",
            "\n",
            "Train Epoch: 316 [0/47500 (0%)]\tLoss: 0.255096\n",
            "Train Epoch: 316 [25600/47500 (54%)]\tLoss: 0.207536\n",
            "\n",
            "Valid set: Average loss: 0.0112, Accuracy: 2091/2499 (84%)\n",
            "\n",
            "Train Epoch: 317 [0/47500 (0%)]\tLoss: 0.239791\n",
            "Train Epoch: 317 [25600/47500 (54%)]\tLoss: 0.226159\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2098/2499 (84%)\n",
            "\n",
            "Train Epoch: 318 [0/47500 (0%)]\tLoss: 0.187407\n",
            "Train Epoch: 318 [25600/47500 (54%)]\tLoss: 0.188479\n",
            "\n",
            "Valid set: Average loss: 0.0106, Accuracy: 2085/2499 (83%)\n",
            "\n",
            "Train Epoch: 319 [0/47500 (0%)]\tLoss: 0.184055\n",
            "Train Epoch: 319 [25600/47500 (54%)]\tLoss: 0.250458\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2110/2499 (84%)\n",
            "\n",
            "Train Epoch: 320 [0/47500 (0%)]\tLoss: 0.275710\n",
            "Train Epoch: 320 [25600/47500 (54%)]\tLoss: 0.188901\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 2089/2499 (84%)\n",
            "\n",
            "Train Epoch: 321 [0/47500 (0%)]\tLoss: 0.175147\n",
            "Train Epoch: 321 [25600/47500 (54%)]\tLoss: 0.183302\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2094/2499 (84%)\n",
            "\n",
            "Train Epoch: 322 [0/47500 (0%)]\tLoss: 0.177253\n",
            "Train Epoch: 322 [25600/47500 (54%)]\tLoss: 0.177272\n",
            "\n",
            "Valid set: Average loss: 0.0099, Accuracy: 2098/2499 (84%)\n",
            "\n",
            "Train Epoch: 323 [0/47500 (0%)]\tLoss: 0.222904\n",
            "Train Epoch: 323 [25600/47500 (54%)]\tLoss: 0.203907\n",
            "\n",
            "Valid set: Average loss: 0.0100, Accuracy: 2098/2499 (84%)\n",
            "\n",
            "Train Epoch: 324 [0/47500 (0%)]\tLoss: 0.258628\n",
            "Train Epoch: 324 [25600/47500 (54%)]\tLoss: 0.166336\n",
            "\n",
            "Valid set: Average loss: 0.0103, Accuracy: 2090/2499 (84%)\n",
            "\n",
            "Train Epoch: 325 [0/47500 (0%)]\tLoss: 0.212996\n",
            "Train Epoch: 325 [25600/47500 (54%)]\tLoss: 0.231610\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 2085/2499 (83%)\n",
            "\n",
            "Train Epoch: 326 [0/47500 (0%)]\tLoss: 0.284866\n",
            "Train Epoch: 326 [25600/47500 (54%)]\tLoss: 0.221813\n",
            "\n",
            "Valid set: Average loss: 0.0103, Accuracy: 2090/2499 (84%)\n",
            "\n",
            "Train Epoch: 327 [0/47500 (0%)]\tLoss: 0.230095\n",
            "Train Epoch: 327 [25600/47500 (54%)]\tLoss: 0.238896\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 2087/2499 (84%)\n",
            "\n",
            "Train Epoch: 328 [0/47500 (0%)]\tLoss: 0.190375\n",
            "Train Epoch: 328 [25600/47500 (54%)]\tLoss: 0.269563\n",
            "\n",
            "Valid set: Average loss: 0.0106, Accuracy: 2092/2499 (84%)\n",
            "\n",
            "Train Epoch: 329 [0/47500 (0%)]\tLoss: 0.198800\n",
            "Train Epoch: 329 [25600/47500 (54%)]\tLoss: 0.214159\n",
            "\n",
            "Valid set: Average loss: 0.0109, Accuracy: 2090/2499 (84%)\n",
            "\n",
            "Train Epoch: 330 [0/47500 (0%)]\tLoss: 0.287206\n",
            "Train Epoch: 330 [25600/47500 (54%)]\tLoss: 0.230047\n",
            "\n",
            "Valid set: Average loss: 0.0103, Accuracy: 2105/2499 (84%)\n",
            "\n",
            "Train Epoch: 331 [0/47500 (0%)]\tLoss: 0.238584\n",
            "Train Epoch: 331 [25600/47500 (54%)]\tLoss: 0.258278\n",
            "\n",
            "Valid set: Average loss: 0.0112, Accuracy: 2093/2499 (84%)\n",
            "\n",
            "Train Epoch: 332 [0/47500 (0%)]\tLoss: 0.305390\n",
            "Train Epoch: 332 [25600/47500 (54%)]\tLoss: 0.241704\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 2077/2499 (83%)\n",
            "\n",
            "Train Epoch: 333 [0/47500 (0%)]\tLoss: 0.241251\n",
            "Train Epoch: 333 [25600/47500 (54%)]\tLoss: 0.256563\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 2101/2499 (84%)\n",
            "\n",
            "Train Epoch: 334 [0/47500 (0%)]\tLoss: 0.287762\n",
            "Train Epoch: 334 [25600/47500 (54%)]\tLoss: 0.183848\n",
            "\n",
            "Valid set: Average loss: 0.0111, Accuracy: 2079/2499 (83%)\n",
            "\n",
            "Train Epoch: 335 [0/47500 (0%)]\tLoss: 0.198275\n",
            "Train Epoch: 335 [25600/47500 (54%)]\tLoss: 0.163417\n",
            "\n",
            "Valid set: Average loss: 0.0104, Accuracy: 2092/2499 (84%)\n",
            "\n",
            "Train Epoch: 336 [0/47500 (0%)]\tLoss: 0.175754\n",
            "Train Epoch: 336 [25600/47500 (54%)]\tLoss: 0.239450\n",
            "\n",
            "Valid set: Average loss: 0.0102, Accuracy: 2097/2499 (84%)\n",
            "\n",
            "Train Epoch: 337 [0/47500 (0%)]\tLoss: 0.302240\n",
            "Train Epoch: 337 [25600/47500 (54%)]\tLoss: 0.237486\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 2089/2499 (84%)\n",
            "\n",
            "Train Epoch: 338 [0/47500 (0%)]\tLoss: 0.167354\n",
            "Train Epoch: 338 [25600/47500 (54%)]\tLoss: 0.173880\n",
            "\n",
            "Valid set: Average loss: 0.0109, Accuracy: 2085/2499 (83%)\n",
            "\n",
            "Train Epoch: 339 [0/47500 (0%)]\tLoss: 0.203701\n",
            "Train Epoch: 339 [25600/47500 (54%)]\tLoss: 0.259306\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2086/2499 (83%)\n",
            "\n",
            "Train Epoch: 340 [0/47500 (0%)]\tLoss: 0.186701\n",
            "Train Epoch: 340 [25600/47500 (54%)]\tLoss: 0.196152\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2095/2499 (84%)\n",
            "\n",
            "Train Epoch: 341 [0/47500 (0%)]\tLoss: 0.261589\n",
            "Train Epoch: 341 [25600/47500 (54%)]\tLoss: 0.186595\n",
            "\n",
            "Valid set: Average loss: 0.0108, Accuracy: 2094/2499 (84%)\n",
            "\n",
            "Train Epoch: 342 [0/47500 (0%)]\tLoss: 0.201566\n",
            "Train Epoch: 342 [25600/47500 (54%)]\tLoss: 0.219567\n",
            "\n",
            "Valid set: Average loss: 0.0103, Accuracy: 2108/2499 (84%)\n",
            "\n",
            "Train Epoch: 343 [0/47500 (0%)]\tLoss: 0.276674\n",
            "Train Epoch: 343 [25600/47500 (54%)]\tLoss: 0.164263\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 2096/2499 (84%)\n",
            "\n",
            "Train Epoch: 344 [0/47500 (0%)]\tLoss: 0.198831\n",
            "Train Epoch: 344 [25600/47500 (54%)]\tLoss: 0.180838\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 2092/2499 (84%)\n",
            "\n",
            "Train Epoch: 345 [0/47500 (0%)]\tLoss: 0.195093\n",
            "Train Epoch: 345 [25600/47500 (54%)]\tLoss: 0.231250\n",
            "\n",
            "Valid set: Average loss: 0.0105, Accuracy: 2100/2499 (84%)\n",
            "\n",
            "Train Epoch: 346 [0/47500 (0%)]\tLoss: 0.235903\n",
            "Train Epoch: 346 [25600/47500 (54%)]\tLoss: 0.202312\n",
            "\n",
            "Valid set: Average loss: 0.0112, Accuracy: 2084/2499 (83%)\n",
            "\n",
            "Train Epoch: 347 [0/47500 (0%)]\tLoss: 0.187211\n",
            "Train Epoch: 347 [25600/47500 (54%)]\tLoss: 0.211890\n",
            "\n",
            "Valid set: Average loss: 0.0107, Accuracy: 2095/2499 (84%)\n",
            "\n",
            "Train Epoch: 348 [0/47500 (0%)]\tLoss: 0.364692\n",
            "Train Epoch: 348 [25600/47500 (54%)]\tLoss: 0.200564\n",
            "\n",
            "Valid set: Average loss: 0.0106, Accuracy: 2098/2499 (84%)\n",
            "\n",
            "Train Epoch: 349 [0/47500 (0%)]\tLoss: 0.274823\n",
            "Train Epoch: 349 [25600/47500 (54%)]\tLoss: 0.228073\n",
            "\n",
            "Valid set: Average loss: 0.0113, Accuracy: 2078/2499 (83%)\n",
            "\n",
            "===================Result=========================\n",
            "Validation Set\n",
            "Error:  0.011271940544247627\n",
            "Acc 0.8315326130452181\n",
            "========================================================\n",
            "Training with  0.01\n",
            "Model(\n",
            "  (model): Sequential(\n",
            "    (0): Dropout(p=0.2, inplace=False)\n",
            "    (1): Conv2d(3, 96, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (2): ReLU()\n",
            "    (3): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Conv2d(96, 192, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU()\n",
            "    (8): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
            "    (9): ReLU()\n",
            "    (10): Dropout(p=0.5, inplace=False)\n",
            "    (11): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (12): ReLU()\n",
            "    (13): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (14): ReLU()\n",
            "    (15): Conv2d(192, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (16): ReLU()\n",
            "    (17): AdaptiveAvgPool2d(output_size=1)\n",
            "    (18): Flatten()\n",
            "  )\n",
            "  (conv_3_192_192_1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv_1_192_192): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (conv_1_192_class): Conv2d(192, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (BN_96): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (BN_192): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (BN_class): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (maxP): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (softMax): Softmax(dim=None)\n",
            "  (flatten): Flatten()\n",
            "  (dropOut_2): Dropout(p=0.2, inplace=False)\n",
            "  (dropOut_5): Dropout(p=0.5, inplace=False)\n",
            "  (relu): ReLU()\n",
            "  (avgPooling): AdaptiveAvgPool2d(output_size=1)\n",
            "  (conv_5_Input_96_1): Conv2d(3, 96, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "  (conv_5_96_192_1): Conv2d(96, 192, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "  (conv_5_96_96_2): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
            "  (conv_5_192_192_2): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "           Dropout-1            [-1, 3, 32, 32]               0\n",
            "            Conv2d-2           [-1, 96, 30, 30]           7,296\n",
            "              ReLU-3           [-1, 96, 30, 30]               0\n",
            "            Conv2d-4           [-1, 96, 14, 14]         230,496\n",
            "              ReLU-5           [-1, 96, 14, 14]               0\n",
            "           Dropout-6           [-1, 96, 14, 14]               0\n",
            "            Conv2d-7          [-1, 192, 12, 12]         460,992\n",
            "              ReLU-8          [-1, 192, 12, 12]               0\n",
            "            Conv2d-9            [-1, 192, 5, 5]         921,792\n",
            "             ReLU-10            [-1, 192, 5, 5]               0\n",
            "          Dropout-11            [-1, 192, 5, 5]               0\n",
            "           Conv2d-12            [-1, 192, 5, 5]         331,968\n",
            "             ReLU-13            [-1, 192, 5, 5]               0\n",
            "           Conv2d-14            [-1, 192, 5, 5]          37,056\n",
            "             ReLU-15            [-1, 192, 5, 5]               0\n",
            "           Conv2d-16             [-1, 10, 5, 5]           1,930\n",
            "             ReLU-17             [-1, 10, 5, 5]               0\n",
            "AdaptiveAvgPool2d-18             [-1, 10, 1, 1]               0\n",
            "          Flatten-19                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 1,991,530\n",
            "Trainable params: 1,991,530\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.45\n",
            "Params size (MB): 7.60\n",
            "Estimated Total Size (MB): 10.06\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [0/47500 (0%)]\tLoss: 2.303235\n",
            "Train Epoch: 0 [25600/47500 (54%)]\tLoss: 2.302841\n",
            "\n",
            "Valid set: Average loss: 0.0369, Accuracy: 257/2499 (10%)\n",
            "\n",
            "Train Epoch: 1 [0/47500 (0%)]\tLoss: 2.302206\n",
            "Train Epoch: 1 [25600/47500 (54%)]\tLoss: 2.301379\n",
            "\n",
            "Valid set: Average loss: 0.0367, Accuracy: 318/2499 (13%)\n",
            "\n",
            "Train Epoch: 2 [0/47500 (0%)]\tLoss: 2.298655\n",
            "Train Epoch: 2 [25600/47500 (54%)]\tLoss: 2.207453\n",
            "\n",
            "Valid set: Average loss: 0.0328, Accuracy: 621/2499 (25%)\n",
            "\n",
            "Train Epoch: 3 [0/47500 (0%)]\tLoss: 2.080544\n",
            "Train Epoch: 3 [25600/47500 (54%)]\tLoss: 1.916739\n",
            "\n",
            "Valid set: Average loss: 0.0286, Accuracy: 796/2499 (32%)\n",
            "\n",
            "Train Epoch: 4 [0/47500 (0%)]\tLoss: 1.782709\n",
            "Train Epoch: 4 [25600/47500 (54%)]\tLoss: 1.668259\n",
            "\n",
            "Valid set: Average loss: 0.0276, Accuracy: 863/2499 (35%)\n",
            "\n",
            "Train Epoch: 5 [0/47500 (0%)]\tLoss: 1.621021\n",
            "Train Epoch: 5 [25600/47500 (54%)]\tLoss: 1.666438\n",
            "\n",
            "Valid set: Average loss: 0.0288, Accuracy: 836/2499 (33%)\n",
            "\n",
            "Train Epoch: 6 [0/47500 (0%)]\tLoss: 1.740046\n",
            "Train Epoch: 6 [25600/47500 (54%)]\tLoss: 1.680249\n",
            "\n",
            "Valid set: Average loss: 0.0265, Accuracy: 1007/2499 (40%)\n",
            "\n",
            "Train Epoch: 7 [0/47500 (0%)]\tLoss: 1.676817\n",
            "Train Epoch: 7 [25600/47500 (54%)]\tLoss: 1.569788\n",
            "\n",
            "Valid set: Average loss: 0.0247, Accuracy: 1044/2499 (42%)\n",
            "\n",
            "Train Epoch: 8 [0/47500 (0%)]\tLoss: 1.470058\n",
            "Train Epoch: 8 [25600/47500 (54%)]\tLoss: 1.505177\n",
            "\n",
            "Valid set: Average loss: 0.0235, Accuracy: 1154/2499 (46%)\n",
            "\n",
            "Train Epoch: 9 [0/47500 (0%)]\tLoss: 1.451729\n",
            "Train Epoch: 9 [25600/47500 (54%)]\tLoss: 1.373443\n",
            "\n",
            "Valid set: Average loss: 0.0226, Accuracy: 1236/2499 (49%)\n",
            "\n",
            "Train Epoch: 10 [0/47500 (0%)]\tLoss: 1.311320\n",
            "Train Epoch: 10 [25600/47500 (54%)]\tLoss: 1.281456\n",
            "\n",
            "Valid set: Average loss: 0.0217, Accuracy: 1267/2499 (51%)\n",
            "\n",
            "Train Epoch: 11 [0/47500 (0%)]\tLoss: 1.230636\n",
            "Train Epoch: 11 [25600/47500 (54%)]\tLoss: 1.325585\n",
            "\n",
            "Valid set: Average loss: 0.0211, Accuracy: 1311/2499 (52%)\n",
            "\n",
            "Train Epoch: 12 [0/47500 (0%)]\tLoss: 1.188741\n",
            "Train Epoch: 12 [25600/47500 (54%)]\tLoss: 1.283406\n",
            "\n",
            "Valid set: Average loss: 0.0217, Accuracy: 1321/2499 (53%)\n",
            "\n",
            "Train Epoch: 13 [0/47500 (0%)]\tLoss: 1.237604\n",
            "Train Epoch: 13 [25600/47500 (54%)]\tLoss: 1.211278\n",
            "\n",
            "Valid set: Average loss: 0.0200, Accuracy: 1398/2499 (56%)\n",
            "\n",
            "Train Epoch: 14 [0/47500 (0%)]\tLoss: 1.220117\n",
            "Train Epoch: 14 [25600/47500 (54%)]\tLoss: 1.111909\n",
            "\n",
            "Valid set: Average loss: 0.0179, Accuracy: 1517/2499 (61%)\n",
            "\n",
            "Train Epoch: 15 [0/47500 (0%)]\tLoss: 1.100573\n",
            "Train Epoch: 15 [25600/47500 (54%)]\tLoss: 1.089666\n",
            "\n",
            "Valid set: Average loss: 0.0185, Accuracy: 1474/2499 (59%)\n",
            "\n",
            "Train Epoch: 16 [0/47500 (0%)]\tLoss: 1.095640\n",
            "Train Epoch: 16 [25600/47500 (54%)]\tLoss: 1.132128\n",
            "\n",
            "Valid set: Average loss: 0.0191, Accuracy: 1484/2499 (59%)\n",
            "\n",
            "Train Epoch: 17 [0/47500 (0%)]\tLoss: 1.006884\n",
            "Train Epoch: 17 [25600/47500 (54%)]\tLoss: 0.970666\n",
            "\n",
            "Valid set: Average loss: 0.0179, Accuracy: 1510/2499 (60%)\n",
            "\n",
            "Train Epoch: 18 [0/47500 (0%)]\tLoss: 1.077676\n",
            "Train Epoch: 18 [25600/47500 (54%)]\tLoss: 1.077357\n",
            "\n",
            "Valid set: Average loss: 0.0174, Accuracy: 1570/2499 (63%)\n",
            "\n",
            "Train Epoch: 19 [0/47500 (0%)]\tLoss: 1.006823\n",
            "Train Epoch: 19 [25600/47500 (54%)]\tLoss: 1.085634\n",
            "\n",
            "Valid set: Average loss: 0.0157, Accuracy: 1618/2499 (65%)\n",
            "\n",
            "Train Epoch: 20 [0/47500 (0%)]\tLoss: 1.001425\n",
            "Train Epoch: 20 [25600/47500 (54%)]\tLoss: 0.995856\n",
            "\n",
            "Valid set: Average loss: 0.0157, Accuracy: 1646/2499 (66%)\n",
            "\n",
            "Train Epoch: 21 [0/47500 (0%)]\tLoss: 0.846438\n",
            "Train Epoch: 21 [25600/47500 (54%)]\tLoss: 0.913047\n",
            "\n",
            "Valid set: Average loss: 0.0154, Accuracy: 1675/2499 (67%)\n",
            "\n",
            "Train Epoch: 22 [0/47500 (0%)]\tLoss: 0.929533\n",
            "Train Epoch: 22 [25600/47500 (54%)]\tLoss: 0.883696\n",
            "\n",
            "Valid set: Average loss: 0.0158, Accuracy: 1651/2499 (66%)\n",
            "\n",
            "Train Epoch: 23 [0/47500 (0%)]\tLoss: 0.849935\n",
            "Train Epoch: 23 [25600/47500 (54%)]\tLoss: 0.793436\n",
            "\n",
            "Valid set: Average loss: 0.0152, Accuracy: 1678/2499 (67%)\n",
            "\n",
            "Train Epoch: 24 [0/47500 (0%)]\tLoss: 0.938288\n",
            "Train Epoch: 24 [25600/47500 (54%)]\tLoss: 0.861782\n",
            "\n",
            "Valid set: Average loss: 0.0143, Accuracy: 1733/2499 (69%)\n",
            "\n",
            "Train Epoch: 25 [0/47500 (0%)]\tLoss: 0.793942\n",
            "Train Epoch: 25 [25600/47500 (54%)]\tLoss: 0.800644\n",
            "\n",
            "Valid set: Average loss: 0.0151, Accuracy: 1703/2499 (68%)\n",
            "\n",
            "Train Epoch: 26 [0/47500 (0%)]\tLoss: 0.751597\n",
            "Train Epoch: 26 [25600/47500 (54%)]\tLoss: 0.804358\n",
            "\n",
            "Valid set: Average loss: 0.0143, Accuracy: 1742/2499 (70%)\n",
            "\n",
            "Train Epoch: 27 [0/47500 (0%)]\tLoss: 0.922637\n",
            "Train Epoch: 27 [25600/47500 (54%)]\tLoss: 0.837890\n",
            "\n",
            "Valid set: Average loss: 0.0134, Accuracy: 1806/2499 (72%)\n",
            "\n",
            "Train Epoch: 28 [0/47500 (0%)]\tLoss: 0.633785\n",
            "Train Epoch: 28 [25600/47500 (54%)]\tLoss: 0.702588\n",
            "\n",
            "Valid set: Average loss: 0.0145, Accuracy: 1755/2499 (70%)\n",
            "\n",
            "Train Epoch: 29 [0/47500 (0%)]\tLoss: 0.703043\n",
            "Train Epoch: 29 [25600/47500 (54%)]\tLoss: 0.713202\n",
            "\n",
            "Valid set: Average loss: 0.0121, Accuracy: 1840/2499 (74%)\n",
            "\n",
            "Train Epoch: 30 [0/47500 (0%)]\tLoss: 0.794341\n",
            "Train Epoch: 30 [25600/47500 (54%)]\tLoss: 0.809640\n",
            "\n",
            "Valid set: Average loss: 0.0132, Accuracy: 1802/2499 (72%)\n",
            "\n",
            "Train Epoch: 31 [0/47500 (0%)]\tLoss: 0.703362\n",
            "Train Epoch: 31 [25600/47500 (54%)]\tLoss: 0.593105\n",
            "\n",
            "Valid set: Average loss: 0.0130, Accuracy: 1816/2499 (73%)\n",
            "\n",
            "Train Epoch: 32 [0/47500 (0%)]\tLoss: 0.755204\n",
            "Train Epoch: 32 [25600/47500 (54%)]\tLoss: 0.662941\n",
            "\n",
            "Valid set: Average loss: 0.0139, Accuracy: 1783/2499 (71%)\n",
            "\n",
            "Train Epoch: 33 [0/47500 (0%)]\tLoss: 0.705125\n",
            "Train Epoch: 33 [25600/47500 (54%)]\tLoss: 0.732961\n",
            "\n",
            "Valid set: Average loss: 0.0137, Accuracy: 1791/2499 (72%)\n",
            "\n",
            "Train Epoch: 34 [0/47500 (0%)]\tLoss: 0.845557\n",
            "Train Epoch: 34 [25600/47500 (54%)]\tLoss: 0.677368\n",
            "\n",
            "Valid set: Average loss: 0.0126, Accuracy: 1842/2499 (74%)\n",
            "\n",
            "Train Epoch: 35 [0/47500 (0%)]\tLoss: 0.663088\n",
            "Train Epoch: 35 [25600/47500 (54%)]\tLoss: 0.688995\n",
            "\n",
            "Valid set: Average loss: 0.0132, Accuracy: 1827/2499 (73%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvwNJmSbYw1L",
        "colab_type": "text"
      },
      "source": [
        "# ConvPool-CNN-A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yrQOb6993WX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training.modifiedModel=[False,False,True,False]\n",
        "training.Procedure()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}